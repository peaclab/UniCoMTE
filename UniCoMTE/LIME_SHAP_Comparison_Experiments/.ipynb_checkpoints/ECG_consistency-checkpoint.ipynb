{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency: Are the explanations consistent for similar classifiers?\n",
    "\n",
    "* Train many logistic regression classifiers with different hyperparameters\n",
    "* Get explanations for each sample in the test set and each classifier\n",
    "* Report Lipschitz estimate for explanations of each classifier\n",
    "\n",
    "Methodology for Sample Selection:\n",
    "* For each class, randomly select one sample. Then, select 2 additional true positive samples of that class with the smallest euclidenan distance to the initial sample chosen.\n",
    "\n",
    "\n",
    "Data Formats Before Wrappers: \n",
    "* Timeseries: 3D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 20:31:33.262525: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 20:31:33.266045: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 20:31:33.277525: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744245093.296444 2479619 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744245093.302218 2479619 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 20:31:33.322924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "from multiprocessing import Pool\n",
    "import functools\n",
    "import sys \n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import mlrose_ky as mlrose\n",
    "#import mlrose\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ecg_analysis.data \n",
    "import ecg_analysis.classifier\n",
    "import explainers_benchmarking as explainers\n",
    "\n",
    "import datasets\n",
    "\n",
    "from explainable_model_ECG import ClfModel as ClfModel\n",
    "from explainable_data_ECG import ClfData as ClfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1: Load in Testing Data, Select Samples of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744245105.843797 2479619 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step\n",
      "(827, 6)\n",
      "[[1.4243224e-06 1.0710077e-07 2.6336946e-07 4.5377445e-07 9.4853863e-07\n",
      "  6.4135390e-09]\n",
      " [2.8897351e-02 2.0066681e-03 3.1778637e-01 2.8277384e-05 4.8343472e-02\n",
      "  3.2049985e-04]\n",
      " [3.1124635e-04 2.9402861e-05 4.1752292e-06 1.9712777e-05 9.3489951e-03\n",
      "  2.4932497e-05]\n",
      " [2.3969111e-09 1.7344941e-09 6.9393674e-10 8.1738605e-10 5.6821343e-09\n",
      "  2.7672636e-10]\n",
      " [5.3062342e-04 3.5334501e-06 3.3941697e-07 1.4301397e-06 2.2422880e-04\n",
      "  4.7077333e-06]]\n",
      "Output predictions saved\n",
      "(None, 4096, 12)\n"
     ]
    }
   ],
   "source": [
    "# load in ECG Testing Set\n",
    "\n",
    "# Select points to explain from testing set\n",
    "\n",
    "# load testing dataset \n",
    "path_to_hdf5_test = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "dataset_name_test = \"tracings\"  \n",
    "\n",
    "# Import data. SEQ is an instance of class ECGSequence\n",
    "seq = datasets.ECGSequence(path_to_hdf5_test, dataset_name_test)  # using default batch size\n",
    "\n",
    "# load pretrained model (still need to compile later) \n",
    "model_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/PretrainedModels/model/model.hdf5\"\n",
    "pre_model = load_model(model_path)  \n",
    "\n",
    "# compile and apply model to testing dataset\n",
    "pre_model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "model_predictions = pre_model.predict(seq,verbose=1)   # y_score is a numpy array with dimensions 827x6. It holds the predictions generated by the model\n",
    "\n",
    "# extra\n",
    "print(model_predictions.shape)\n",
    "print(model_predictions[:5])\n",
    "\n",
    "# Generate dataframe\n",
    "np.save(\"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/dnn_output.npy\", model_predictions)\n",
    "print(\"Output predictions saved\")\n",
    "\n",
    "print(pre_model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECG_one_d_labels(model_predictions, onehot_labels = True):\n",
    "    '''\n",
    "    \n",
    "    Purpose: turn one-hot encoding (N,d) array into (Nx1) vector of classes\n",
    "\n",
    "    Input: \n",
    "    model_predictions: 2D array of probabilities or one-hot encodings (827x6)\n",
    "    onehot_labels: boolean variable \n",
    "\n",
    "    Output: \n",
    "    (Nx1) vector of classes\n",
    "\n",
    "    Comments: \n",
    "    The sample class is the class that exceeds the threshold\n",
    "    If there are >1 classes that exceed the threshold, a tuple will be used to store the multiple classes \n",
    "    '''\n",
    "    \n",
    "\n",
    "    if not onehot_labels:\n",
    "        # establish threshold\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((model_predictions - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        # add normal prob\n",
    "        probability_n = np.column_stack((normal_prob, model_predictions))\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "\n",
    "        # make mask\n",
    "        mask = probability_n >= new_threshold\n",
    "    else:\n",
    "        print(model_predictions.shape)\n",
    "\n",
    "        mask = model_predictions == 1\n",
    "\n",
    "        # Ensure each row has at least one '1'\n",
    "        # no_positive_class is a column vector\n",
    "        # Find rows with all False (no '1') # rows with all false becomes true\n",
    "        no_positive_class = ~mask.any(axis=1) \n",
    "        \n",
    "        # Expand mask by adding a new first column of zeros\n",
    "        mask = np.column_stack((no_positive_class, mask))\n",
    "    \n",
    "\n",
    "    sample_classes = []\n",
    "    for row in mask:\n",
    "        passing_indices = np.where(row)[0]\n",
    "        if len(passing_indices) > 1:  # If more than one indices pass\n",
    "            if not onehot_labels: \n",
    "                # calc exceedances    \n",
    "                exceedances = row - new_threshold\n",
    "                # Get class with the highest exceedance\n",
    "                max_class = np.argmax(exceedances)\n",
    "                sample_classes.append(max_class)\n",
    "            else:\n",
    "                sample_classes.append(tuple(sorted(passing_indices)))  # Ensure passing indices are sorted in ascending order\n",
    "        elif len(passing_indices) == 0:  # no passes\n",
    "            sample_classes.append(0) \n",
    "        else:\n",
    "            sample_classes.append(passing_indices[0])  \n",
    "\n",
    "    return sample_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 6)\n"
     ]
    }
   ],
   "source": [
    "# load predictions to make y_pred\n",
    "model_predictions = np.load(\"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/dnn_output.npy\")\n",
    "# make y_pred\n",
    "y_pred = ECG_one_d_labels(model_predictions, onehot_labels = False)\n",
    "\n",
    "# make y_true\n",
    "y_true_2D = pd.read_csv('/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/annotations/gold_standard.csv').values\n",
    "# convert 2D to 1D\n",
    "y_true = ECG_one_d_labels(y_true_2D, onehot_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:0, True Label: 0, Predicted Label: 0\n",
      "Index:1, True Label: 3, Predicted Label: 3\n",
      "Index:2, True Label: 0, Predicted Label: 0\n",
      "Index:3, True Label: 0, Predicted Label: 0\n",
      "Index:4, True Label: 0, Predicted Label: 0\n",
      "Index:5, True Label: 0, Predicted Label: 0\n",
      "Index:6, True Label: 0, Predicted Label: 0\n",
      "Index:7, True Label: 0, Predicted Label: 0\n",
      "Index:8, True Label: 0, Predicted Label: 0\n",
      "Index:9, True Label: 0, Predicted Label: 0\n",
      "Index:10, True Label: 0, Predicted Label: 0\n",
      "Index:11, True Label: 0, Predicted Label: 0\n",
      "Index:12, True Label: 1, Predicted Label: 1\n",
      "Index:13, True Label: 0, Predicted Label: 0\n",
      "Index:14, True Label: 0, Predicted Label: 0\n",
      "Index:15, True Label: (np.int64(1), np.int64(3)), Predicted Label: 3\n",
      "Index:16, True Label: 0, Predicted Label: 0\n",
      "Index:17, True Label: 0, Predicted Label: 0\n",
      "Index:18, True Label: (np.int64(1), np.int64(3)), Predicted Label: 3\n",
      "Index:19, True Label: 0, Predicted Label: 0\n",
      "Index:20, True Label: 0, Predicted Label: 0\n",
      "Index:21, True Label: 0, Predicted Label: 0\n",
      "Index:22, True Label: 0, Predicted Label: 4\n",
      "Index:23, True Label: 6, Predicted Label: 6\n",
      "Index:24, True Label: 0, Predicted Label: 0\n",
      "Index:25, True Label: 0, Predicted Label: 0\n",
      "Index:26, True Label: 0, Predicted Label: 0\n",
      "Index:27, True Label: 0, Predicted Label: 0\n",
      "Index:28, True Label: 3, Predicted Label: 3\n",
      "Index:29, True Label: 0, Predicted Label: 0\n",
      "Index:30, True Label: 0, Predicted Label: 0\n",
      "Index:31, True Label: 0, Predicted Label: 0\n",
      "Index:32, True Label: 1, Predicted Label: 1\n",
      "Index:33, True Label: 6, Predicted Label: 6\n",
      "Index:34, True Label: 0, Predicted Label: 0\n",
      "Index:35, True Label: 0, Predicted Label: 0\n",
      "Index:36, True Label: 0, Predicted Label: 0\n",
      "Index:37, True Label: 0, Predicted Label: 0\n",
      "Index:38, True Label: 0, Predicted Label: 0\n",
      "Index:39, True Label: 0, Predicted Label: 0\n",
      "Index:40, True Label: 4, Predicted Label: 4\n",
      "Index:41, True Label: 0, Predicted Label: 0\n",
      "Index:42, True Label: 0, Predicted Label: 0\n",
      "Index:43, True Label: 0, Predicted Label: 0\n",
      "Index:44, True Label: 0, Predicted Label: 0\n",
      "Index:45, True Label: 0, Predicted Label: 0\n",
      "Index:46, True Label: 0, Predicted Label: 0\n",
      "Index:47, True Label: 0, Predicted Label: 0\n",
      "Index:48, True Label: 0, Predicted Label: 0\n",
      "Index:49, True Label: 0, Predicted Label: 0\n",
      "Index:50, True Label: 0, Predicted Label: 0\n",
      "Index:51, True Label: 0, Predicted Label: 0\n",
      "Index:52, True Label: 0, Predicted Label: 0\n",
      "Index:53, True Label: 0, Predicted Label: 0\n",
      "Index:54, True Label: 0, Predicted Label: 0\n",
      "Index:55, True Label: 0, Predicted Label: 0\n",
      "Index:56, True Label: 0, Predicted Label: 0\n",
      "Index:57, True Label: 1, Predicted Label: 0\n",
      "Index:58, True Label: 3, Predicted Label: 3\n",
      "Index:59, True Label: 0, Predicted Label: 0\n",
      "Index:60, True Label: 0, Predicted Label: 0\n",
      "Index:61, True Label: 0, Predicted Label: 0\n",
      "Index:62, True Label: 0, Predicted Label: 0\n",
      "Index:63, True Label: 0, Predicted Label: 0\n",
      "Index:64, True Label: 0, Predicted Label: 0\n",
      "Index:65, True Label: 0, Predicted Label: 0\n",
      "Index:66, True Label: 0, Predicted Label: 0\n",
      "Index:67, True Label: (np.int64(1), np.int64(2)), Predicted Label: 2\n",
      "Index:68, True Label: (np.int64(1), np.int64(4)), Predicted Label: 1\n",
      "Index:69, True Label: 6, Predicted Label: 6\n",
      "Index:70, True Label: 0, Predicted Label: 0\n",
      "Index:71, True Label: 0, Predicted Label: 0\n",
      "Index:72, True Label: 0, Predicted Label: 0\n",
      "Index:73, True Label: 0, Predicted Label: 0\n",
      "Index:74, True Label: 0, Predicted Label: 0\n",
      "Index:75, True Label: 4, Predicted Label: 4\n",
      "Index:76, True Label: 0, Predicted Label: 0\n",
      "Index:77, True Label: 1, Predicted Label: 1\n",
      "Index:78, True Label: 0, Predicted Label: 0\n",
      "Index:79, True Label: 0, Predicted Label: 0\n",
      "Index:80, True Label: 0, Predicted Label: 0\n",
      "Index:81, True Label: 0, Predicted Label: 0\n",
      "Index:82, True Label: 0, Predicted Label: 0\n",
      "Index:83, True Label: 0, Predicted Label: 0\n",
      "Index:84, True Label: 0, Predicted Label: 0\n",
      "Index:85, True Label: 1, Predicted Label: 1\n",
      "Index:86, True Label: 0, Predicted Label: 0\n",
      "Index:87, True Label: 0, Predicted Label: 0\n",
      "Index:88, True Label: 0, Predicted Label: 0\n",
      "Index:89, True Label: 0, Predicted Label: 0\n",
      "Index:90, True Label: 0, Predicted Label: 0\n",
      "Index:91, True Label: (np.int64(1), np.int64(3)), Predicted Label: 3\n",
      "Index:92, True Label: 0, Predicted Label: 0\n",
      "Index:93, True Label: 0, Predicted Label: 0\n",
      "Index:94, True Label: 0, Predicted Label: 0\n",
      "Index:95, True Label: 0, Predicted Label: 0\n",
      "Index:96, True Label: 1, Predicted Label: 1\n",
      "Index:97, True Label: 0, Predicted Label: 0\n",
      "Index:98, True Label: 4, Predicted Label: 4\n",
      "Index:99, True Label: 3, Predicted Label: 3\n",
      "Index:100, True Label: 0, Predicted Label: 0\n",
      "Index:101, True Label: 0, Predicted Label: 0\n",
      "Index:102, True Label: 0, Predicted Label: 0\n",
      "Index:103, True Label: 0, Predicted Label: 0\n",
      "Index:104, True Label: 3, Predicted Label: 3\n",
      "Index:105, True Label: 0, Predicted Label: 0\n",
      "Index:106, True Label: 2, Predicted Label: 2\n",
      "Index:107, True Label: 0, Predicted Label: 0\n",
      "Index:108, True Label: 6, Predicted Label: 6\n",
      "Index:109, True Label: 0, Predicted Label: 0\n",
      "Index:110, True Label: 0, Predicted Label: 2\n",
      "Index:111, True Label: 0, Predicted Label: 0\n",
      "Index:112, True Label: 0, Predicted Label: 0\n",
      "Index:113, True Label: 0, Predicted Label: 0\n",
      "Index:114, True Label: 0, Predicted Label: 0\n",
      "Index:115, True Label: 0, Predicted Label: 0\n",
      "Index:116, True Label: 0, Predicted Label: 0\n",
      "Index:117, True Label: 0, Predicted Label: 0\n",
      "Index:118, True Label: 0, Predicted Label: 0\n",
      "Index:119, True Label: 0, Predicted Label: 0\n",
      "Index:120, True Label: 5, Predicted Label: 5\n",
      "Index:121, True Label: 0, Predicted Label: 6\n",
      "Index:122, True Label: 0, Predicted Label: 0\n",
      "Index:123, True Label: 0, Predicted Label: 0\n",
      "Index:124, True Label: 0, Predicted Label: 0\n",
      "Index:125, True Label: 0, Predicted Label: 0\n",
      "Index:126, True Label: 6, Predicted Label: 6\n",
      "Index:127, True Label: 0, Predicted Label: 0\n",
      "Index:128, True Label: 6, Predicted Label: 6\n",
      "Index:129, True Label: 0, Predicted Label: 0\n",
      "Index:130, True Label: 0, Predicted Label: 0\n",
      "Index:131, True Label: 0, Predicted Label: 0\n",
      "Index:132, True Label: 0, Predicted Label: 0\n",
      "Index:133, True Label: 0, Predicted Label: 0\n",
      "Index:134, True Label: 0, Predicted Label: 0\n",
      "Index:135, True Label: 0, Predicted Label: 0\n",
      "Index:136, True Label: 0, Predicted Label: 0\n",
      "Index:137, True Label: 6, Predicted Label: 6\n",
      "Index:138, True Label: 0, Predicted Label: 0\n",
      "Index:139, True Label: 0, Predicted Label: 0\n",
      "Index:140, True Label: 0, Predicted Label: 0\n",
      "Index:141, True Label: 3, Predicted Label: 3\n",
      "Index:142, True Label: 0, Predicted Label: 0\n",
      "Index:143, True Label: 0, Predicted Label: 0\n",
      "Index:144, True Label: 0, Predicted Label: 0\n",
      "Index:145, True Label: 0, Predicted Label: 0\n",
      "Index:146, True Label: 0, Predicted Label: 0\n",
      "Index:147, True Label: 0, Predicted Label: 0\n",
      "Index:148, True Label: 6, Predicted Label: 2\n",
      "Index:149, True Label: 0, Predicted Label: 0\n",
      "Index:150, True Label: 0, Predicted Label: 0\n",
      "Index:151, True Label: 4, Predicted Label: 0\n",
      "Index:152, True Label: 0, Predicted Label: 0\n",
      "Index:153, True Label: 0, Predicted Label: 0\n",
      "Index:154, True Label: 0, Predicted Label: 0\n",
      "Index:155, True Label: 0, Predicted Label: 0\n",
      "Index:156, True Label: 0, Predicted Label: 0\n",
      "Index:157, True Label: 0, Predicted Label: 0\n",
      "Index:158, True Label: 0, Predicted Label: 0\n",
      "Index:159, True Label: 1, Predicted Label: 1\n",
      "Index:160, True Label: 0, Predicted Label: 0\n",
      "Index:161, True Label: 0, Predicted Label: 0\n",
      "Index:162, True Label: 0, Predicted Label: 0\n",
      "Index:163, True Label: 0, Predicted Label: 0\n",
      "Index:164, True Label: 0, Predicted Label: 0\n",
      "Index:165, True Label: 0, Predicted Label: 0\n",
      "Index:166, True Label: 6, Predicted Label: 6\n",
      "Index:167, True Label: 0, Predicted Label: 0\n",
      "Index:168, True Label: 0, Predicted Label: 0\n",
      "Index:169, True Label: 0, Predicted Label: 0\n",
      "Index:170, True Label: 5, Predicted Label: 0\n",
      "Index:171, True Label: 0, Predicted Label: 0\n",
      "Index:172, True Label: 0, Predicted Label: 0\n",
      "Index:173, True Label: 0, Predicted Label: 0\n",
      "Index:174, True Label: 0, Predicted Label: 0\n",
      "Index:175, True Label: 0, Predicted Label: 0\n",
      "Index:176, True Label: 0, Predicted Label: 0\n",
      "Index:177, True Label: 0, Predicted Label: 0\n",
      "Index:178, True Label: 6, Predicted Label: 6\n",
      "Index:179, True Label: 0, Predicted Label: 0\n",
      "Index:180, True Label: 0, Predicted Label: 0\n",
      "Index:181, True Label: 0, Predicted Label: 0\n",
      "Index:182, True Label: 0, Predicted Label: 0\n",
      "Index:183, True Label: 0, Predicted Label: 0\n",
      "Index:184, True Label: 6, Predicted Label: 6\n",
      "Index:185, True Label: 3, Predicted Label: 3\n",
      "Index:186, True Label: 0, Predicted Label: 0\n",
      "Index:187, True Label: 0, Predicted Label: 0\n",
      "Index:188, True Label: 4, Predicted Label: 4\n",
      "Index:189, True Label: 0, Predicted Label: 0\n",
      "Index:190, True Label: 0, Predicted Label: 0\n",
      "Index:191, True Label: 0, Predicted Label: 0\n",
      "Index:192, True Label: 0, Predicted Label: 0\n",
      "Index:193, True Label: 0, Predicted Label: 0\n",
      "Index:194, True Label: 0, Predicted Label: 0\n",
      "Index:195, True Label: 6, Predicted Label: 6\n",
      "Index:196, True Label: 0, Predicted Label: 0\n",
      "Index:197, True Label: 0, Predicted Label: 0\n",
      "Index:198, True Label: 0, Predicted Label: 0\n",
      "Index:199, True Label: 0, Predicted Label: 0\n",
      "Index:200, True Label: 0, Predicted Label: 0\n",
      "Index:201, True Label: 0, Predicted Label: 0\n",
      "Index:202, True Label: 0, Predicted Label: 0\n",
      "Index:203, True Label: 0, Predicted Label: 0\n",
      "Index:204, True Label: 0, Predicted Label: 0\n",
      "Index:205, True Label: 0, Predicted Label: 0\n",
      "Index:206, True Label: 0, Predicted Label: 0\n",
      "Index:207, True Label: 0, Predicted Label: 0\n",
      "Index:208, True Label: 0, Predicted Label: 0\n",
      "Index:209, True Label: 0, Predicted Label: 0\n",
      "Index:210, True Label: 0, Predicted Label: 0\n",
      "Index:211, True Label: 0, Predicted Label: 0\n",
      "Index:212, True Label: 0, Predicted Label: 0\n",
      "Index:213, True Label: 0, Predicted Label: 0\n",
      "Index:214, True Label: 0, Predicted Label: 0\n",
      "Index:215, True Label: 0, Predicted Label: 0\n",
      "Index:216, True Label: 0, Predicted Label: 0\n",
      "Index:217, True Label: 3, Predicted Label: 3\n",
      "Index:218, True Label: 0, Predicted Label: 0\n",
      "Index:219, True Label: 0, Predicted Label: 0\n",
      "Index:220, True Label: 0, Predicted Label: 0\n",
      "Index:221, True Label: 0, Predicted Label: 0\n",
      "Index:222, True Label: 0, Predicted Label: 0\n",
      "Index:223, True Label: 0, Predicted Label: 0\n",
      "Index:224, True Label: 0, Predicted Label: 0\n",
      "Index:225, True Label: 0, Predicted Label: 0\n",
      "Index:226, True Label: 0, Predicted Label: 0\n",
      "Index:227, True Label: 0, Predicted Label: 0\n",
      "Index:228, True Label: 0, Predicted Label: 0\n",
      "Index:229, True Label: 0, Predicted Label: 0\n",
      "Index:230, True Label: 0, Predicted Label: 0\n",
      "Index:231, True Label: 0, Predicted Label: 0\n",
      "Index:232, True Label: 0, Predicted Label: 0\n",
      "Index:233, True Label: 0, Predicted Label: 0\n",
      "Index:234, True Label: 0, Predicted Label: 0\n",
      "Index:235, True Label: 0, Predicted Label: 0\n",
      "Index:236, True Label: 0, Predicted Label: 0\n",
      "Index:237, True Label: 0, Predicted Label: 0\n",
      "Index:238, True Label: 0, Predicted Label: 0\n",
      "Index:239, True Label: 0, Predicted Label: 0\n",
      "Index:240, True Label: 0, Predicted Label: 0\n",
      "Index:241, True Label: 2, Predicted Label: 2\n",
      "Index:242, True Label: 0, Predicted Label: 0\n",
      "Index:243, True Label: 0, Predicted Label: 0\n",
      "Index:244, True Label: 0, Predicted Label: 0\n",
      "Index:245, True Label: 0, Predicted Label: 0\n",
      "Index:246, True Label: 0, Predicted Label: 0\n",
      "Index:247, True Label: 6, Predicted Label: 6\n",
      "Index:248, True Label: 0, Predicted Label: 0\n",
      "Index:249, True Label: 1, Predicted Label: 1\n",
      "Index:250, True Label: 0, Predicted Label: 0\n",
      "Index:251, True Label: 3, Predicted Label: 3\n",
      "Index:252, True Label: 0, Predicted Label: 0\n",
      "Index:253, True Label: 3, Predicted Label: 3\n",
      "Index:254, True Label: 0, Predicted Label: 0\n",
      "Index:255, True Label: 2, Predicted Label: 2\n",
      "Index:256, True Label: 0, Predicted Label: 0\n",
      "Index:257, True Label: 0, Predicted Label: 0\n",
      "Index:258, True Label: 0, Predicted Label: 0\n",
      "Index:259, True Label: 5, Predicted Label: 5\n",
      "Index:260, True Label: 0, Predicted Label: 0\n",
      "Index:261, True Label: 0, Predicted Label: 0\n",
      "Index:262, True Label: 0, Predicted Label: 0\n",
      "Index:263, True Label: 0, Predicted Label: 0\n",
      "Index:264, True Label: 0, Predicted Label: 0\n",
      "Index:265, True Label: 0, Predicted Label: 0\n",
      "Index:266, True Label: 0, Predicted Label: 0\n",
      "Index:267, True Label: 0, Predicted Label: 0\n",
      "Index:268, True Label: 0, Predicted Label: 0\n",
      "Index:269, True Label: 0, Predicted Label: 0\n",
      "Index:270, True Label: 0, Predicted Label: 0\n",
      "Index:271, True Label: 0, Predicted Label: 0\n",
      "Index:272, True Label: 0, Predicted Label: 0\n",
      "Index:273, True Label: 0, Predicted Label: 0\n",
      "Index:274, True Label: 0, Predicted Label: 0\n",
      "Index:275, True Label: 0, Predicted Label: 0\n",
      "Index:276, True Label: 0, Predicted Label: 0\n",
      "Index:277, True Label: 0, Predicted Label: 0\n",
      "Index:278, True Label: 0, Predicted Label: 0\n",
      "Index:279, True Label: 3, Predicted Label: 3\n",
      "Index:280, True Label: 0, Predicted Label: 0\n",
      "Index:281, True Label: 0, Predicted Label: 0\n",
      "Index:282, True Label: 0, Predicted Label: 0\n",
      "Index:283, True Label: 0, Predicted Label: 0\n",
      "Index:284, True Label: 0, Predicted Label: 0\n",
      "Index:285, True Label: 0, Predicted Label: 0\n",
      "Index:286, True Label: 0, Predicted Label: 0\n",
      "Index:287, True Label: 0, Predicted Label: 0\n",
      "Index:288, True Label: 0, Predicted Label: 0\n",
      "Index:289, True Label: 2, Predicted Label: 2\n",
      "Index:290, True Label: 0, Predicted Label: 0\n",
      "Index:291, True Label: 0, Predicted Label: 0\n",
      "Index:292, True Label: 0, Predicted Label: 0\n",
      "Index:293, True Label: 3, Predicted Label: 3\n",
      "Index:294, True Label: 0, Predicted Label: 0\n",
      "Index:295, True Label: 0, Predicted Label: 0\n",
      "Index:296, True Label: 0, Predicted Label: 0\n",
      "Index:297, True Label: 0, Predicted Label: 0\n",
      "Index:298, True Label: 2, Predicted Label: 2\n",
      "Index:299, True Label: 0, Predicted Label: 0\n",
      "Index:300, True Label: 0, Predicted Label: 0\n",
      "Index:301, True Label: 0, Predicted Label: 0\n",
      "Index:302, True Label: 3, Predicted Label: 3\n",
      "Index:303, True Label: 0, Predicted Label: 0\n",
      "Index:304, True Label: 0, Predicted Label: 0\n",
      "Index:305, True Label: 0, Predicted Label: 0\n",
      "Index:306, True Label: 0, Predicted Label: 0\n",
      "Index:307, True Label: 0, Predicted Label: 0\n",
      "Index:308, True Label: 0, Predicted Label: 0\n",
      "Index:309, True Label: 6, Predicted Label: 6\n",
      "Index:310, True Label: 0, Predicted Label: 0\n",
      "Index:311, True Label: 0, Predicted Label: 0\n",
      "Index:312, True Label: 0, Predicted Label: 0\n",
      "Index:313, True Label: 2, Predicted Label: 2\n",
      "Index:314, True Label: 0, Predicted Label: 0\n",
      "Index:315, True Label: 0, Predicted Label: 0\n",
      "Index:316, True Label: 0, Predicted Label: 0\n",
      "Index:317, True Label: 0, Predicted Label: 0\n",
      "Index:318, True Label: 0, Predicted Label: 0\n",
      "Index:319, True Label: 0, Predicted Label: 0\n",
      "Index:320, True Label: 4, Predicted Label: 4\n",
      "Index:321, True Label: 0, Predicted Label: 0\n",
      "Index:322, True Label: 0, Predicted Label: 0\n",
      "Index:323, True Label: 0, Predicted Label: 0\n",
      "Index:324, True Label: 0, Predicted Label: 0\n",
      "Index:325, True Label: 0, Predicted Label: 0\n",
      "Index:326, True Label: 0, Predicted Label: 0\n",
      "Index:327, True Label: 0, Predicted Label: 0\n",
      "Index:328, True Label: 0, Predicted Label: 0\n",
      "Index:329, True Label: 0, Predicted Label: 0\n",
      "Index:330, True Label: 2, Predicted Label: 2\n",
      "Index:331, True Label: 0, Predicted Label: 0\n",
      "Index:332, True Label: 0, Predicted Label: 0\n",
      "Index:333, True Label: 0, Predicted Label: 0\n",
      "Index:334, True Label: 0, Predicted Label: 0\n",
      "Index:335, True Label: 0, Predicted Label: 0\n",
      "Index:336, True Label: 1, Predicted Label: 1\n",
      "Index:337, True Label: 0, Predicted Label: 0\n",
      "Index:338, True Label: 0, Predicted Label: 0\n",
      "Index:339, True Label: 0, Predicted Label: 0\n",
      "Index:340, True Label: 0, Predicted Label: 0\n",
      "Index:341, True Label: 3, Predicted Label: 3\n",
      "Index:342, True Label: (np.int64(1), np.int64(2)), Predicted Label: 2\n",
      "Index:343, True Label: 4, Predicted Label: 4\n",
      "Index:344, True Label: 1, Predicted Label: 1\n",
      "Index:345, True Label: 3, Predicted Label: 3\n",
      "Index:346, True Label: 0, Predicted Label: 0\n",
      "Index:347, True Label: 0, Predicted Label: 0\n",
      "Index:348, True Label: 5, Predicted Label: 5\n",
      "Index:349, True Label: 0, Predicted Label: 0\n",
      "Index:350, True Label: 0, Predicted Label: 0\n",
      "Index:351, True Label: 0, Predicted Label: 0\n",
      "Index:352, True Label: 0, Predicted Label: 0\n",
      "Index:353, True Label: 3, Predicted Label: 3\n",
      "Index:354, True Label: 0, Predicted Label: 0\n",
      "Index:355, True Label: 5, Predicted Label: 0\n",
      "Index:356, True Label: 0, Predicted Label: 2\n",
      "Index:357, True Label: 0, Predicted Label: 0\n",
      "Index:358, True Label: 0, Predicted Label: 0\n",
      "Index:359, True Label: 0, Predicted Label: 0\n",
      "Index:360, True Label: 0, Predicted Label: 0\n",
      "Index:361, True Label: 0, Predicted Label: 0\n",
      "Index:362, True Label: 0, Predicted Label: 0\n",
      "Index:363, True Label: 0, Predicted Label: 0\n",
      "Index:364, True Label: 0, Predicted Label: 0\n",
      "Index:365, True Label: 2, Predicted Label: 2\n",
      "Index:366, True Label: 0, Predicted Label: 0\n",
      "Index:367, True Label: 2, Predicted Label: 2\n",
      "Index:368, True Label: 5, Predicted Label: 0\n",
      "Index:369, True Label: 0, Predicted Label: 0\n",
      "Index:370, True Label: 0, Predicted Label: 0\n",
      "Index:371, True Label: 0, Predicted Label: 0\n",
      "Index:372, True Label: 0, Predicted Label: 0\n",
      "Index:373, True Label: 0, Predicted Label: 0\n",
      "Index:374, True Label: 0, Predicted Label: 0\n",
      "Index:375, True Label: 0, Predicted Label: 0\n",
      "Index:376, True Label: 6, Predicted Label: 6\n",
      "Index:377, True Label: 1, Predicted Label: 1\n",
      "Index:378, True Label: 0, Predicted Label: 0\n",
      "Index:379, True Label: 2, Predicted Label: 2\n",
      "Index:380, True Label: 0, Predicted Label: 0\n",
      "Index:381, True Label: 0, Predicted Label: 0\n",
      "Index:382, True Label: 3, Predicted Label: 3\n",
      "Index:383, True Label: 0, Predicted Label: 0\n",
      "Index:384, True Label: 3, Predicted Label: 3\n",
      "Index:385, True Label: 0, Predicted Label: 0\n",
      "Index:386, True Label: 0, Predicted Label: 0\n",
      "Index:387, True Label: 0, Predicted Label: 0\n",
      "Index:388, True Label: 0, Predicted Label: 0\n",
      "Index:389, True Label: 0, Predicted Label: 0\n",
      "Index:390, True Label: 1, Predicted Label: 1\n",
      "Index:391, True Label: 0, Predicted Label: 0\n",
      "Index:392, True Label: 0, Predicted Label: 0\n",
      "Index:393, True Label: 0, Predicted Label: 0\n",
      "Index:394, True Label: 0, Predicted Label: 0\n",
      "Index:395, True Label: 0, Predicted Label: 0\n",
      "Index:396, True Label: 0, Predicted Label: 0\n",
      "Index:397, True Label: 6, Predicted Label: 6\n",
      "Index:398, True Label: 0, Predicted Label: 0\n",
      "Index:399, True Label: 0, Predicted Label: 0\n",
      "Index:400, True Label: 0, Predicted Label: 0\n",
      "Index:401, True Label: 0, Predicted Label: 0\n",
      "Index:402, True Label: 0, Predicted Label: 0\n",
      "Index:403, True Label: 0, Predicted Label: 0\n",
      "Index:404, True Label: 0, Predicted Label: 0\n",
      "Index:405, True Label: 0, Predicted Label: 0\n",
      "Index:406, True Label: 0, Predicted Label: 0\n",
      "Index:407, True Label: 0, Predicted Label: 0\n",
      "Index:408, True Label: 5, Predicted Label: 5\n",
      "Index:409, True Label: 0, Predicted Label: 0\n",
      "Index:410, True Label: 0, Predicted Label: 0\n",
      "Index:411, True Label: 0, Predicted Label: 0\n",
      "Index:412, True Label: 0, Predicted Label: 0\n",
      "Index:413, True Label: 0, Predicted Label: 0\n",
      "Index:414, True Label: 1, Predicted Label: 1\n",
      "Index:415, True Label: (np.int64(2), np.int64(5)), Predicted Label: 2\n",
      "Index:416, True Label: 0, Predicted Label: 0\n",
      "Index:417, True Label: 6, Predicted Label: 6\n",
      "Index:418, True Label: 0, Predicted Label: 0\n",
      "Index:419, True Label: 0, Predicted Label: 0\n",
      "Index:420, True Label: 1, Predicted Label: 1\n",
      "Index:421, True Label: 0, Predicted Label: 0\n",
      "Index:422, True Label: 0, Predicted Label: 0\n",
      "Index:423, True Label: 0, Predicted Label: 0\n",
      "Index:424, True Label: 0, Predicted Label: 0\n",
      "Index:425, True Label: 0, Predicted Label: 0\n",
      "Index:426, True Label: 0, Predicted Label: 0\n",
      "Index:427, True Label: 0, Predicted Label: 0\n",
      "Index:428, True Label: 0, Predicted Label: 0\n",
      "Index:429, True Label: 0, Predicted Label: 0\n",
      "Index:430, True Label: 0, Predicted Label: 0\n",
      "Index:431, True Label: 0, Predicted Label: 0\n",
      "Index:432, True Label: 0, Predicted Label: 0\n",
      "Index:433, True Label: 0, Predicted Label: 0\n",
      "Index:434, True Label: 0, Predicted Label: 0\n",
      "Index:435, True Label: 2, Predicted Label: 2\n",
      "Index:436, True Label: 0, Predicted Label: 0\n",
      "Index:437, True Label: 0, Predicted Label: 0\n",
      "Index:438, True Label: 0, Predicted Label: 0\n",
      "Index:439, True Label: 6, Predicted Label: 6\n",
      "Index:440, True Label: 0, Predicted Label: 0\n",
      "Index:441, True Label: 0, Predicted Label: 0\n",
      "Index:442, True Label: 0, Predicted Label: 0\n",
      "Index:443, True Label: 0, Predicted Label: 0\n",
      "Index:444, True Label: 0, Predicted Label: 0\n",
      "Index:445, True Label: 0, Predicted Label: 0\n",
      "Index:446, True Label: 4, Predicted Label: 4\n",
      "Index:447, True Label: 0, Predicted Label: 0\n",
      "Index:448, True Label: 0, Predicted Label: 0\n",
      "Index:449, True Label: 0, Predicted Label: 0\n",
      "Index:450, True Label: 0, Predicted Label: 0\n",
      "Index:451, True Label: 0, Predicted Label: 0\n",
      "Index:452, True Label: 0, Predicted Label: 0\n",
      "Index:453, True Label: 0, Predicted Label: 0\n",
      "Index:454, True Label: 0, Predicted Label: 0\n",
      "Index:455, True Label: 0, Predicted Label: 0\n",
      "Index:456, True Label: 0, Predicted Label: 0\n",
      "Index:457, True Label: 0, Predicted Label: 0\n",
      "Index:458, True Label: 6, Predicted Label: 6\n",
      "Index:459, True Label: 0, Predicted Label: 0\n",
      "Index:460, True Label: 0, Predicted Label: 0\n",
      "Index:461, True Label: 0, Predicted Label: 0\n",
      "Index:462, True Label: 0, Predicted Label: 0\n",
      "Index:463, True Label: 1, Predicted Label: 1\n",
      "Index:464, True Label: 0, Predicted Label: 0\n",
      "Index:465, True Label: 0, Predicted Label: 0\n",
      "Index:466, True Label: 0, Predicted Label: 0\n",
      "Index:467, True Label: 0, Predicted Label: 0\n",
      "Index:468, True Label: 0, Predicted Label: 0\n",
      "Index:469, True Label: (np.int64(2), np.int64(6)), Predicted Label: 2\n",
      "Index:470, True Label: 0, Predicted Label: 0\n",
      "Index:471, True Label: 0, Predicted Label: 0\n",
      "Index:472, True Label: 0, Predicted Label: 0\n",
      "Index:473, True Label: 0, Predicted Label: 0\n",
      "Index:474, True Label: 0, Predicted Label: 0\n",
      "Index:475, True Label: 0, Predicted Label: 0\n",
      "Index:476, True Label: 0, Predicted Label: 0\n",
      "Index:477, True Label: 0, Predicted Label: 0\n",
      "Index:478, True Label: 0, Predicted Label: 0\n",
      "Index:479, True Label: 0, Predicted Label: 0\n",
      "Index:480, True Label: 0, Predicted Label: 0\n",
      "Index:481, True Label: 6, Predicted Label: 6\n",
      "Index:482, True Label: 0, Predicted Label: 0\n",
      "Index:483, True Label: 0, Predicted Label: 0\n",
      "Index:484, True Label: 0, Predicted Label: 0\n",
      "Index:485, True Label: (np.int64(3), np.int64(5)), Predicted Label: 3\n",
      "Index:486, True Label: 0, Predicted Label: 0\n",
      "Index:487, True Label: 0, Predicted Label: 0\n",
      "Index:488, True Label: 0, Predicted Label: 0\n",
      "Index:489, True Label: 2, Predicted Label: 2\n",
      "Index:490, True Label: 0, Predicted Label: 0\n",
      "Index:491, True Label: 0, Predicted Label: 0\n",
      "Index:492, True Label: 6, Predicted Label: 6\n",
      "Index:493, True Label: 3, Predicted Label: 3\n",
      "Index:494, True Label: 0, Predicted Label: 0\n",
      "Index:495, True Label: 4, Predicted Label: 4\n",
      "Index:496, True Label: 0, Predicted Label: 0\n",
      "Index:497, True Label: 0, Predicted Label: 0\n",
      "Index:498, True Label: 3, Predicted Label: 3\n",
      "Index:499, True Label: 0, Predicted Label: 0\n",
      "Index:500, True Label: 2, Predicted Label: 2\n",
      "Index:501, True Label: 5, Predicted Label: 5\n",
      "Index:502, True Label: 0, Predicted Label: 2\n",
      "Index:503, True Label: 6, Predicted Label: 6\n",
      "Index:504, True Label: 0, Predicted Label: 0\n",
      "Index:505, True Label: 0, Predicted Label: 0\n",
      "Index:506, True Label: 0, Predicted Label: 0\n",
      "Index:507, True Label: 0, Predicted Label: 0\n",
      "Index:508, True Label: 0, Predicted Label: 0\n",
      "Index:509, True Label: 0, Predicted Label: 0\n",
      "Index:510, True Label: 0, Predicted Label: 0\n",
      "Index:511, True Label: 0, Predicted Label: 0\n",
      "Index:512, True Label: 0, Predicted Label: 0\n",
      "Index:513, True Label: 0, Predicted Label: 0\n",
      "Index:514, True Label: 2, Predicted Label: 2\n",
      "Index:515, True Label: 0, Predicted Label: 0\n",
      "Index:516, True Label: 0, Predicted Label: 0\n",
      "Index:517, True Label: 0, Predicted Label: 0\n",
      "Index:518, True Label: 0, Predicted Label: 0\n",
      "Index:519, True Label: 0, Predicted Label: 0\n",
      "Index:520, True Label: 0, Predicted Label: 0\n",
      "Index:521, True Label: 0, Predicted Label: 0\n",
      "Index:522, True Label: (np.int64(3), np.int64(6)), Predicted Label: 3\n",
      "Index:523, True Label: 0, Predicted Label: 0\n",
      "Index:524, True Label: 0, Predicted Label: 0\n",
      "Index:525, True Label: 4, Predicted Label: 4\n",
      "Index:526, True Label: 0, Predicted Label: 0\n",
      "Index:527, True Label: 0, Predicted Label: 0\n",
      "Index:528, True Label: 0, Predicted Label: 0\n",
      "Index:529, True Label: 0, Predicted Label: 0\n",
      "Index:530, True Label: 0, Predicted Label: 0\n",
      "Index:531, True Label: 0, Predicted Label: 0\n",
      "Index:532, True Label: 0, Predicted Label: 0\n",
      "Index:533, True Label: 0, Predicted Label: 0\n",
      "Index:534, True Label: 3, Predicted Label: 3\n",
      "Index:535, True Label: 0, Predicted Label: 0\n",
      "Index:536, True Label: 0, Predicted Label: 0\n",
      "Index:537, True Label: 0, Predicted Label: 0\n",
      "Index:538, True Label: 0, Predicted Label: 0\n",
      "Index:539, True Label: 0, Predicted Label: 0\n",
      "Index:540, True Label: 0, Predicted Label: 0\n",
      "Index:541, True Label: 2, Predicted Label: 2\n",
      "Index:542, True Label: 0, Predicted Label: 0\n",
      "Index:543, True Label: 6, Predicted Label: 6\n",
      "Index:544, True Label: 0, Predicted Label: 0\n",
      "Index:545, True Label: 6, Predicted Label: 6\n",
      "Index:546, True Label: 0, Predicted Label: 0\n",
      "Index:547, True Label: 0, Predicted Label: 0\n",
      "Index:548, True Label: 5, Predicted Label: 0\n",
      "Index:549, True Label: 0, Predicted Label: 0\n",
      "Index:550, True Label: 0, Predicted Label: 0\n",
      "Index:551, True Label: 0, Predicted Label: 0\n",
      "Index:552, True Label: 0, Predicted Label: 0\n",
      "Index:553, True Label: 1, Predicted Label: 1\n",
      "Index:554, True Label: 0, Predicted Label: 0\n",
      "Index:555, True Label: 2, Predicted Label: 2\n",
      "Index:556, True Label: 0, Predicted Label: 0\n",
      "Index:557, True Label: 0, Predicted Label: 0\n",
      "Index:558, True Label: 0, Predicted Label: 0\n",
      "Index:559, True Label: 0, Predicted Label: 0\n",
      "Index:560, True Label: 0, Predicted Label: 0\n",
      "Index:561, True Label: 0, Predicted Label: 0\n",
      "Index:562, True Label: 0, Predicted Label: 0\n",
      "Index:563, True Label: 6, Predicted Label: 6\n",
      "Index:564, True Label: 5, Predicted Label: 5\n",
      "Index:565, True Label: 0, Predicted Label: 0\n",
      "Index:566, True Label: 0, Predicted Label: 0\n",
      "Index:567, True Label: 0, Predicted Label: 0\n",
      "Index:568, True Label: 0, Predicted Label: 0\n",
      "Index:569, True Label: 0, Predicted Label: 0\n",
      "Index:570, True Label: 0, Predicted Label: 0\n",
      "Index:571, True Label: 0, Predicted Label: 0\n",
      "Index:572, True Label: 5, Predicted Label: 5\n",
      "Index:573, True Label: 0, Predicted Label: 0\n",
      "Index:574, True Label: 3, Predicted Label: 3\n",
      "Index:575, True Label: 0, Predicted Label: 0\n",
      "Index:576, True Label: 0, Predicted Label: 0\n",
      "Index:577, True Label: 0, Predicted Label: 0\n",
      "Index:578, True Label: 4, Predicted Label: 4\n",
      "Index:579, True Label: 4, Predicted Label: 4\n",
      "Index:580, True Label: 0, Predicted Label: 0\n",
      "Index:581, True Label: 6, Predicted Label: 6\n",
      "Index:582, True Label: 0, Predicted Label: 0\n",
      "Index:583, True Label: 0, Predicted Label: 0\n",
      "Index:584, True Label: 3, Predicted Label: 3\n",
      "Index:585, True Label: 0, Predicted Label: 0\n",
      "Index:586, True Label: 0, Predicted Label: 0\n",
      "Index:587, True Label: 0, Predicted Label: 0\n",
      "Index:588, True Label: 0, Predicted Label: 0\n",
      "Index:589, True Label: 0, Predicted Label: 0\n",
      "Index:590, True Label: 0, Predicted Label: 0\n",
      "Index:591, True Label: 0, Predicted Label: 0\n",
      "Index:592, True Label: 0, Predicted Label: 0\n",
      "Index:593, True Label: 0, Predicted Label: 0\n",
      "Index:594, True Label: 3, Predicted Label: 3\n",
      "Index:595, True Label: 0, Predicted Label: 0\n",
      "Index:596, True Label: 0, Predicted Label: 0\n",
      "Index:597, True Label: 0, Predicted Label: 0\n",
      "Index:598, True Label: 0, Predicted Label: 0\n",
      "Index:599, True Label: 0, Predicted Label: 0\n",
      "Index:600, True Label: 0, Predicted Label: 0\n",
      "Index:601, True Label: 0, Predicted Label: 0\n",
      "Index:602, True Label: 0, Predicted Label: 0\n",
      "Index:603, True Label: 0, Predicted Label: 0\n",
      "Index:604, True Label: 0, Predicted Label: 0\n",
      "Index:605, True Label: 0, Predicted Label: 0\n",
      "Index:606, True Label: 0, Predicted Label: 0\n",
      "Index:607, True Label: 2, Predicted Label: 2\n",
      "Index:608, True Label: 0, Predicted Label: 0\n",
      "Index:609, True Label: 0, Predicted Label: 0\n",
      "Index:610, True Label: 0, Predicted Label: 0\n",
      "Index:611, True Label: 0, Predicted Label: 0\n",
      "Index:612, True Label: 0, Predicted Label: 0\n",
      "Index:613, True Label: 6, Predicted Label: 6\n",
      "Index:614, True Label: 0, Predicted Label: 0\n",
      "Index:615, True Label: 0, Predicted Label: 0\n",
      "Index:616, True Label: 0, Predicted Label: 0\n",
      "Index:617, True Label: 0, Predicted Label: 0\n",
      "Index:618, True Label: 2, Predicted Label: 2\n",
      "Index:619, True Label: 0, Predicted Label: 0\n",
      "Index:620, True Label: 0, Predicted Label: 0\n",
      "Index:621, True Label: 0, Predicted Label: 0\n",
      "Index:622, True Label: 0, Predicted Label: 0\n",
      "Index:623, True Label: 0, Predicted Label: 0\n",
      "Index:624, True Label: 0, Predicted Label: 0\n",
      "Index:625, True Label: 0, Predicted Label: 0\n",
      "Index:626, True Label: 2, Predicted Label: 2\n",
      "Index:627, True Label: 0, Predicted Label: 0\n",
      "Index:628, True Label: 0, Predicted Label: 0\n",
      "Index:629, True Label: 6, Predicted Label: 6\n",
      "Index:630, True Label: 0, Predicted Label: 0\n",
      "Index:631, True Label: 0, Predicted Label: 0\n",
      "Index:632, True Label: 0, Predicted Label: 0\n",
      "Index:633, True Label: 0, Predicted Label: 0\n",
      "Index:634, True Label: 0, Predicted Label: 0\n",
      "Index:635, True Label: 0, Predicted Label: 0\n",
      "Index:636, True Label: 0, Predicted Label: 0\n",
      "Index:637, True Label: 0, Predicted Label: 0\n",
      "Index:638, True Label: 0, Predicted Label: 0\n",
      "Index:639, True Label: 0, Predicted Label: 0\n",
      "Index:640, True Label: 0, Predicted Label: 0\n",
      "Index:641, True Label: 0, Predicted Label: 0\n",
      "Index:642, True Label: 0, Predicted Label: 0\n",
      "Index:643, True Label: 0, Predicted Label: 0\n",
      "Index:644, True Label: 0, Predicted Label: 0\n",
      "Index:645, True Label: 0, Predicted Label: 4\n",
      "Index:646, True Label: 0, Predicted Label: 6\n",
      "Index:647, True Label: 0, Predicted Label: 0\n",
      "Index:648, True Label: 0, Predicted Label: 0\n",
      "Index:649, True Label: 0, Predicted Label: 0\n",
      "Index:650, True Label: 0, Predicted Label: 0\n",
      "Index:651, True Label: 0, Predicted Label: 0\n",
      "Index:652, True Label: 0, Predicted Label: 0\n",
      "Index:653, True Label: 0, Predicted Label: 0\n",
      "Index:654, True Label: 0, Predicted Label: 0\n",
      "Index:655, True Label: 0, Predicted Label: 0\n",
      "Index:656, True Label: 0, Predicted Label: 0\n",
      "Index:657, True Label: 0, Predicted Label: 0\n",
      "Index:658, True Label: 0, Predicted Label: 0\n",
      "Index:659, True Label: 6, Predicted Label: 6\n",
      "Index:660, True Label: 0, Predicted Label: 0\n",
      "Index:661, True Label: 0, Predicted Label: 0\n",
      "Index:662, True Label: 2, Predicted Label: 3\n",
      "Index:663, True Label: 0, Predicted Label: 0\n",
      "Index:664, True Label: 0, Predicted Label: 0\n",
      "Index:665, True Label: 0, Predicted Label: 0\n",
      "Index:666, True Label: 2, Predicted Label: 2\n",
      "Index:667, True Label: 2, Predicted Label: 2\n",
      "Index:668, True Label: 0, Predicted Label: 0\n",
      "Index:669, True Label: 0, Predicted Label: 0\n",
      "Index:670, True Label: 0, Predicted Label: 0\n",
      "Index:671, True Label: 0, Predicted Label: 0\n",
      "Index:672, True Label: 2, Predicted Label: 2\n",
      "Index:673, True Label: 0, Predicted Label: 0\n",
      "Index:674, True Label: 0, Predicted Label: 0\n",
      "Index:675, True Label: 0, Predicted Label: 0\n",
      "Index:676, True Label: 0, Predicted Label: 0\n",
      "Index:677, True Label: 0, Predicted Label: 0\n",
      "Index:678, True Label: 0, Predicted Label: 4\n",
      "Index:679, True Label: 0, Predicted Label: 0\n",
      "Index:680, True Label: 0, Predicted Label: 0\n",
      "Index:681, True Label: 0, Predicted Label: 6\n",
      "Index:682, True Label: 4, Predicted Label: 4\n",
      "Index:683, True Label: 2, Predicted Label: 2\n",
      "Index:684, True Label: 0, Predicted Label: 0\n",
      "Index:685, True Label: 0, Predicted Label: 0\n",
      "Index:686, True Label: 0, Predicted Label: 0\n",
      "Index:687, True Label: 6, Predicted Label: 6\n",
      "Index:688, True Label: 0, Predicted Label: 0\n",
      "Index:689, True Label: 0, Predicted Label: 0\n",
      "Index:690, True Label: 0, Predicted Label: 0\n",
      "Index:691, True Label: 0, Predicted Label: 0\n",
      "Index:692, True Label: 0, Predicted Label: 0\n",
      "Index:693, True Label: 0, Predicted Label: 0\n",
      "Index:694, True Label: 0, Predicted Label: 0\n",
      "Index:695, True Label: 1, Predicted Label: 1\n",
      "Index:696, True Label: 0, Predicted Label: 0\n",
      "Index:697, True Label: 0, Predicted Label: 0\n",
      "Index:698, True Label: 0, Predicted Label: 0\n",
      "Index:699, True Label: 0, Predicted Label: 0\n",
      "Index:700, True Label: 0, Predicted Label: 0\n",
      "Index:701, True Label: 0, Predicted Label: 0\n",
      "Index:702, True Label: 0, Predicted Label: 0\n",
      "Index:703, True Label: 0, Predicted Label: 0\n",
      "Index:704, True Label: 0, Predicted Label: 0\n",
      "Index:705, True Label: 0, Predicted Label: 0\n",
      "Index:706, True Label: 0, Predicted Label: 0\n",
      "Index:707, True Label: 0, Predicted Label: 0\n",
      "Index:708, True Label: 0, Predicted Label: 0\n",
      "Index:709, True Label: 0, Predicted Label: 0\n",
      "Index:710, True Label: 0, Predicted Label: 0\n",
      "Index:711, True Label: 0, Predicted Label: 0\n",
      "Index:712, True Label: (np.int64(1), np.int64(2)), Predicted Label: 2\n",
      "Index:713, True Label: 0, Predicted Label: 0\n",
      "Index:714, True Label: 0, Predicted Label: 0\n",
      "Index:715, True Label: 0, Predicted Label: 0\n",
      "Index:716, True Label: 0, Predicted Label: 0\n",
      "Index:717, True Label: 0, Predicted Label: 0\n",
      "Index:718, True Label: 6, Predicted Label: 6\n",
      "Index:719, True Label: 0, Predicted Label: 0\n",
      "Index:720, True Label: 1, Predicted Label: 0\n",
      "Index:721, True Label: 4, Predicted Label: 4\n",
      "Index:722, True Label: 0, Predicted Label: 0\n",
      "Index:723, True Label: 6, Predicted Label: 6\n",
      "Index:724, True Label: 0, Predicted Label: 0\n",
      "Index:725, True Label: 2, Predicted Label: 2\n",
      "Index:726, True Label: 0, Predicted Label: 0\n",
      "Index:727, True Label: 0, Predicted Label: 0\n",
      "Index:728, True Label: 0, Predicted Label: 4\n",
      "Index:729, True Label: 0, Predicted Label: 0\n",
      "Index:730, True Label: 6, Predicted Label: 6\n",
      "Index:731, True Label: 0, Predicted Label: 0\n",
      "Index:732, True Label: 0, Predicted Label: 0\n",
      "Index:733, True Label: 0, Predicted Label: 0\n",
      "Index:734, True Label: 0, Predicted Label: 0\n",
      "Index:735, True Label: 0, Predicted Label: 0\n",
      "Index:736, True Label: 0, Predicted Label: 0\n",
      "Index:737, True Label: 0, Predicted Label: 0\n",
      "Index:738, True Label: 0, Predicted Label: 0\n",
      "Index:739, True Label: 0, Predicted Label: 0\n",
      "Index:740, True Label: 0, Predicted Label: 0\n",
      "Index:741, True Label: 0, Predicted Label: 0\n",
      "Index:742, True Label: 0, Predicted Label: 0\n",
      "Index:743, True Label: 0, Predicted Label: 0\n",
      "Index:744, True Label: 2, Predicted Label: 2\n",
      "Index:745, True Label: 0, Predicted Label: 0\n",
      "Index:746, True Label: 0, Predicted Label: 0\n",
      "Index:747, True Label: 4, Predicted Label: 4\n",
      "Index:748, True Label: 0, Predicted Label: 0\n",
      "Index:749, True Label: 0, Predicted Label: 0\n",
      "Index:750, True Label: 0, Predicted Label: 0\n",
      "Index:751, True Label: 0, Predicted Label: 0\n",
      "Index:752, True Label: 0, Predicted Label: 0\n",
      "Index:753, True Label: 2, Predicted Label: 2\n",
      "Index:754, True Label: 0, Predicted Label: 0\n",
      "Index:755, True Label: 0, Predicted Label: 0\n",
      "Index:756, True Label: 0, Predicted Label: 0\n",
      "Index:757, True Label: 0, Predicted Label: 0\n",
      "Index:758, True Label: 1, Predicted Label: 0\n",
      "Index:759, True Label: 2, Predicted Label: 2\n",
      "Index:760, True Label: 0, Predicted Label: 0\n",
      "Index:761, True Label: 0, Predicted Label: 0\n",
      "Index:762, True Label: 0, Predicted Label: 0\n",
      "Index:763, True Label: 0, Predicted Label: 0\n",
      "Index:764, True Label: 0, Predicted Label: 2\n",
      "Index:765, True Label: 0, Predicted Label: 0\n",
      "Index:766, True Label: 0, Predicted Label: 0\n",
      "Index:767, True Label: 6, Predicted Label: 6\n",
      "Index:768, True Label: 0, Predicted Label: 0\n",
      "Index:769, True Label: 0, Predicted Label: 0\n",
      "Index:770, True Label: 0, Predicted Label: 0\n",
      "Index:771, True Label: 0, Predicted Label: 0\n",
      "Index:772, True Label: 0, Predicted Label: 0\n",
      "Index:773, True Label: 0, Predicted Label: 0\n",
      "Index:774, True Label: 0, Predicted Label: 0\n",
      "Index:775, True Label: 0, Predicted Label: 0\n",
      "Index:776, True Label: 0, Predicted Label: 0\n",
      "Index:777, True Label: 0, Predicted Label: 0\n",
      "Index:778, True Label: 0, Predicted Label: 0\n",
      "Index:779, True Label: 0, Predicted Label: 0\n",
      "Index:780, True Label: 0, Predicted Label: 0\n",
      "Index:781, True Label: 0, Predicted Label: 0\n",
      "Index:782, True Label: 0, Predicted Label: 0\n",
      "Index:783, True Label: 0, Predicted Label: 0\n",
      "Index:784, True Label: 0, Predicted Label: 0\n",
      "Index:785, True Label: 0, Predicted Label: 0\n",
      "Index:786, True Label: 0, Predicted Label: 0\n",
      "Index:787, True Label: 3, Predicted Label: 3\n",
      "Index:788, True Label: 0, Predicted Label: 0\n",
      "Index:789, True Label: 6, Predicted Label: 6\n",
      "Index:790, True Label: (np.int64(1), np.int64(2)), Predicted Label: 2\n",
      "Index:791, True Label: 0, Predicted Label: 0\n",
      "Index:792, True Label: 0, Predicted Label: 0\n",
      "Index:793, True Label: 0, Predicted Label: 0\n",
      "Index:794, True Label: 0, Predicted Label: 0\n",
      "Index:795, True Label: 0, Predicted Label: 0\n",
      "Index:796, True Label: 0, Predicted Label: 0\n",
      "Index:797, True Label: 0, Predicted Label: 0\n",
      "Index:798, True Label: 0, Predicted Label: 0\n",
      "Index:799, True Label: 0, Predicted Label: 0\n",
      "Index:800, True Label: 0, Predicted Label: 0\n",
      "Index:801, True Label: 0, Predicted Label: 0\n",
      "Index:802, True Label: 0, Predicted Label: 0\n",
      "Index:803, True Label: 0, Predicted Label: 0\n",
      "Index:804, True Label: 0, Predicted Label: 0\n",
      "Index:805, True Label: 0, Predicted Label: 0\n",
      "Index:806, True Label: 0, Predicted Label: 0\n",
      "Index:807, True Label: 0, Predicted Label: 0\n",
      "Index:808, True Label: 0, Predicted Label: 0\n",
      "Index:809, True Label: 0, Predicted Label: 0\n",
      "Index:810, True Label: 0, Predicted Label: 0\n",
      "Index:811, True Label: 0, Predicted Label: 0\n",
      "Index:812, True Label: 0, Predicted Label: 0\n",
      "Index:813, True Label: 0, Predicted Label: 0\n",
      "Index:814, True Label: 0, Predicted Label: 0\n",
      "Index:815, True Label: 0, Predicted Label: 0\n",
      "Index:816, True Label: 0, Predicted Label: 0\n",
      "Index:817, True Label: 0, Predicted Label: 0\n",
      "Index:818, True Label: 0, Predicted Label: 0\n",
      "Index:819, True Label: 0, Predicted Label: 0\n",
      "Index:820, True Label: 0, Predicted Label: 0\n",
      "Index:821, True Label: 0, Predicted Label: 0\n",
      "Index:822, True Label: 0, Predicted Label: 0\n",
      "Index:823, True Label: 0, Predicted Label: 0\n",
      "Index:824, True Label: 0, Predicted Label: 0\n",
      "Index:825, True Label: 0, Predicted Label: 0\n",
      "Index:826, True Label: 1, Predicted Label: 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 21, 24, 25, 26, 27, 29, 30, 31, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 97, 100, 101, 102, 103, 105, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 186, 187, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 248, 250, 252, 254, 256, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 294, 295, 296, 297, 299, 300, 301, 303, 304, 305, 306, 307, 308, 310, 311, 312, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 337, 338, 339, 340, 346, 347, 349, 350, 351, 352, 354, 357, 358, 359, 360, 361, 362, 363, 364, 366, 369, 370, 371, 372, 373, 374, 375, 378, 380, 381, 383, 385, 386, 387, 388, 389, 391, 392, 393, 394, 395, 396, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 409, 410, 411, 412, 413, 416, 418, 419, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 436, 437, 438, 440, 441, 442, 443, 444, 445, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 459, 460, 461, 462, 464, 465, 466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 486, 487, 488, 490, 491, 494, 496, 497, 499, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 515, 516, 517, 518, 519, 520, 521, 523, 524, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 542, 544, 546, 547, 549, 550, 551, 552, 554, 556, 557, 558, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570, 571, 573, 575, 576, 577, 580, 582, 583, 585, 586, 587, 588, 589, 590, 591, 592, 593, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 608, 609, 610, 611, 612, 614, 615, 616, 617, 619, 620, 621, 622, 623, 624, 625, 627, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 660, 661, 663, 664, 665, 668, 669, 670, 671, 673, 674, 675, 676, 677, 679, 680, 684, 685, 686, 688, 689, 690, 691, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 713, 714, 715, 716, 717, 719, 722, 724, 726, 727, 729, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 745, 746, 748, 749, 750, 751, 752, 754, 755, 756, 757, 760, 761, 762, 763, 765, 766, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 788, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825] indices match the case defined above:\n",
      "(true_select = 0, pred_select = 0)\n"
     ]
    }
   ],
   "source": [
    "# select indices/conditions for CoMTE\n",
    "true_select = 0 #UPDATE HERE FOR OTHER CLASSES\n",
    "pred_select = 0 #UPDATE HERE FOR OTHER CLASSES\n",
    "\n",
    "# find relevant indices\n",
    "indices_test = []\n",
    "for idx, (true, pred) in enumerate(zip(y_true, y_pred)):\n",
    "    print(f\"Index:{idx}, True Label: {true}, Predicted Label: {pred}\") # print elements\n",
    "    if true ==  true_select and pred == pred_select:\n",
    "        indices_test.append(idx)   \n",
    "        \n",
    "print('\\n\\n\\n')\n",
    "print(f\"The {indices_test} indices match the case defined above:\\n(true_select = {true_select}, pred_select = {pred_select})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 12)\n"
     ]
    }
   ],
   "source": [
    "# select testing point\n",
    "\n",
    "# get testing point\n",
    "test_point = seq._getsample_(253)\n",
    "# wrap test point \n",
    "test_df = ClfData.wrap_df_test_point(test_point)\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2: Select Nearest Neighbor Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for getting nearest neighbor samples\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KDTree\n",
    "class nearest_neighbor_samples:\n",
    "    '''\n",
    "        Purpose: \n",
    "        - find true positives\n",
    "        - append them to KDTree\n",
    "        - find nearest neighbor samples that are true positives of the same class\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self, clf, timeseries, labels, silent=True,\n",
    "                     num_distractors=2, dont_stop=False):#,\n",
    "                     # threads=multiprocessing.cpu_count()):\n",
    "        self.clf = clf\n",
    "        self.timeseries = timeseries\n",
    "        self.labels = labels\n",
    "        self.silent = silent\n",
    "        self.num_distractors = num_distractors\n",
    "        if hasattr(clf, \"metrics\") and clf.metrics is not None:\n",
    "            self.metrics = clf.metrics\n",
    "        else:\n",
    "            self.metrics = self.clf.steps[0][1].column_names\n",
    "        self.dont_stop = dont_stop\n",
    "        if hasattr(clf, \"window_size\") and clf.window_size is not None:\n",
    "            self.window_size = clf.window_size\n",
    "        else:\n",
    "            self.window_size = len(timeseries.loc[\n",
    "                timeseries.index.get_level_values('node_id')[0]])\n",
    "        self.tree = None\n",
    "        self.per_class_trees = None\n",
    "        #self.threads = threads\n",
    "        self.classes_to_test = [1,2,3,4,5,6]\n",
    "        \n",
    "\n",
    "    \n",
    "    def construct_per_class_trees(self):\n",
    "            \"\"\"Used to choose distractors\"\"\"\n",
    "            if self.per_class_trees is not None:\n",
    "    \n",
    "                for c, tree in self.per_class_trees.items():\n",
    "                    num_indices = len(tree.data)  # The number of points in the KDTree\n",
    "                    print(f\"Class {c} has {num_indices} indices.\")\n",
    "                return\n",
    "            self.per_class_trees = {}\n",
    "            self.per_class_node_indices = {c: [] for c in self.clf.classes_}\n",
    "            print('making predictions for per class trees')\n",
    "            preds = self.clf.predict(self.timeseries)\n",
    "    \n",
    "            from collections import Counter\n",
    "            #checking preds ...\n",
    "            print('Validate Predictions')\n",
    "            counter = Counter(preds)\n",
    "            # Print unique items and their frequencies\n",
    "            for item, freq in counter.items():\n",
    "                print(f\"{item}: {freq}\")\n",
    "    \n",
    "            true_positive_node_ids = {c: [] for c in self.clf.classes_}\n",
    "            \n",
    "            for pred, (idx, row) in zip(preds, self.labels.iterrows()):\n",
    "                if isinstance(row['label'], tuple):  # skip tuples for now - not sure how to handle them in MLRose Optimization\n",
    "                    continue\n",
    "                if row['label'] == pred:\n",
    "                    if isinstance(idx, int): # wrap single datapoints in array\n",
    "                        idx = [idx]\n",
    "                    true_positive_node_ids[pred].append(idx[0])\n",
    "        \n",
    "            # validation\n",
    "            print(\"\\nTrue Positive Dictionary Stats\")\n",
    "            for key, value in true_positive_node_ids.items():\n",
    "                print(f\"Key: {key}, Length of value: {len(value)}\")\n",
    "            \n",
    "            \n",
    "            print('making per class trees')\n",
    "            print(self.clf.classes_)\n",
    "            for c in self.clf.classes_:\n",
    "                print(c)\n",
    "                dataset = []\n",
    "                for node_id in true_positive_node_ids[c]:\n",
    "                    # The below syntax of timeseries.loc[[node_id], :, :] is extremely fragile. The first two ranges index into the multi-index\n",
    "                    # while the third range indexes the columns. But anything other than \":\" for the third range causes the code to crash, apparently\n",
    "                    # due to ambiguity. See the Warning here: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#using-slicers\n",
    "                    try:\n",
    "                        sliced_node = self.timeseries.loc[[node_id], :, :]\n",
    "                    except pd.errors.IndexingError: # try slicing with fallback\n",
    "                        sliced_node = self.timeseries.loc[[node_id], :]\n",
    "                    dataset.append(sliced_node.values.T.flatten())\n",
    "                    self.per_class_node_indices[c].append(node_id)\n",
    "                if dataset:\n",
    "                    self.per_class_trees[c] = KDTree(np.stack(dataset))\n",
    "            if not self.silent:\n",
    "                logging.info(\"Finished constructing per class kdtree\")\n",
    "\n",
    "\n",
    "    def get_random_tps(self):\n",
    "        '''\n",
    "            This function should generate one random sample for each class in self.classes_to_test\n",
    "\n",
    "        '''\n",
    "        # print out the structure of the KD tree\n",
    "        print(\"\\nKDTree structure (underlying tree representation):\")\n",
    "        print(self.per_class_trees)\n",
    "\n",
    "        \n",
    "        # get a random sample for each class in KDTree, store in tuple\n",
    "        random_samples = []\n",
    "\n",
    "        for c in self.classes_to_test:\n",
    "            if c in self.per_class_trees:  # Ensure the class has a KDTree\n",
    "                # Get a random index from the class tree\n",
    "                random_idx = np.random.randint(len(self.per_class_trees[c].data))\n",
    "                print(f'random index is {random_idx}')\n",
    "                # extract distractor\n",
    "                random_sample = self.timeseries.loc[[self.per_class_node_indices[c][random_idx]], :, :]\n",
    "                random_samples.append((c, random_sample))\n",
    "            else:\n",
    "                print(f\"No KDTree found for class {c}\")\n",
    "        return random_samples\n",
    "\n",
    "\n",
    "    def get_all_samples(self):\n",
    "        '''\n",
    "            This funciton should generate all samples, and store them in tuples\n",
    "        '''\n",
    "        print('Getting all samples')\n",
    "        # start with constructing per class KD trees\n",
    "        self.construct_per_class_trees()\n",
    "\n",
    "        # get random true positives\n",
    "        random_samples = self.get_random_tps()\n",
    "\n",
    "        # iterate through each of the random samples to get Knn\n",
    "        n_distractors = 2\n",
    "\n",
    "        # Initialize a list to store distractors (nearest neighbors)\n",
    "        distractors = defaultdict(list)\n",
    "        print(len(random_samples))\n",
    "        # For each random sample, find nearest neighbors\n",
    "        for class_id, sample in random_samples:\n",
    "            print(class_id)\n",
    "            print(sample)\n",
    "            # code for querying...\n",
    "            for idx in self.per_class_trees[class_id].query(\n",
    "                sample.values.T.flatten().reshape(1, -1),\n",
    "                k=n_distractors)[1].flatten():\n",
    "                \n",
    "                print(f'idx for nn distractor is: {idx}')\n",
    "                \n",
    "                try:\n",
    "                    sliced_distractor = self.timeseries.loc[[self.per_class_node_indices[class_id][idx]], :, :]\n",
    "                except pd.errors.IndexingError: # try slicing with fallback\n",
    "                    sliced_distractor = self.timeseries.loc[[self.per_class_node_indices[class_id][idx]], :]\n",
    "                    sliced_distractor['node_id'] = [idx]\n",
    "                    sliced_distractor.set_index('node_id', inplace=True) # aka sample_id\n",
    "                    \n",
    "                distractors[class_id].append((class_id, sliced_distractor))\n",
    "            distractors[class_id].append((class_id, sample))\n",
    "        \n",
    "        return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# define classifier methods\n",
    "\n",
    "\"\"\"\n",
    "Part 1: A Classifier that works with COMLEX\n",
    "\n",
    "The classifier must have 2 capabilities:\n",
    "1. Predict a class ie: class 0 in classes {0, 1}\n",
    "2. Predict the probability for each class\n",
    "-ie: [0.1, 0.9]\n",
    "\n",
    "and\n",
    "\n",
    "Be able to execute capability 1 and 2 on a PANDAS dataframe,\n",
    "returning an array of corresponding predictions.\n",
    "\n",
    "\n",
    "\n",
    "input:\n",
    "    samples to be classified (pandas multiindex dataframe)\n",
    "\n",
    "output: \n",
    "    for contrived_classification: length N list of classes\n",
    "\n",
    "    for contrived_classification_proba: \n",
    "            length N list of 1x7 np arrays\n",
    "\"\"\"\n",
    "\n",
    "# load pretrained model (still need to compile later) \n",
    "model_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/PretrainedModels/model/model.hdf5\"\n",
    "pre_model = load_model(model_path)  \n",
    "pre_model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "\n",
    "class BasicClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "    import os\n",
    "    \n",
    "    @staticmethod\n",
    "    def contrived_classification(pandas_dfs):\n",
    "        import os\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "        # convert 2D pandas df to 3D dataframe (N,4096,12)\n",
    "        array_3d = pandas_dfs.to_numpy().reshape(int(pandas_dfs.shape[0]/4096), 4096, 12)\n",
    "\n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 0)    \n",
    "        \n",
    "    \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        # analyze model output with thresholding\n",
    "        # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        \n",
    "        # Add normal_prob as a new column\n",
    "        probability_n = np.column_stack((normal_prob, probability))     \n",
    "\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        mask = probability_n >= new_threshold\n",
    "        sample_classes = []  # init list for appends later\n",
    "        \n",
    "        for row, mask in zip(probability_n, mask):\n",
    "            passing_indices = np.where(mask)[0]\n",
    "            if len(passing_indices) > 1:  # If more than one indices pass\n",
    "                # find margin between threshold and probability\n",
    "                diff_array = row - new_threshold\n",
    "                passing_index = np.argmax(diff_array)\n",
    "                # append the index that has the highest margin\n",
    "                sample_classes.append(passing_index)\n",
    "            \n",
    "            elif len(passing_indices) == 0:  # no passes\n",
    "                sample_classes.append(0) \n",
    "            else:\n",
    "                sample_classes.append(passing_indices[0])  # Select the first (or adjust logic)\n",
    "                \n",
    "        return sample_classes\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def contrived_classification_proba(pandas_dfs):\n",
    "        import os\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "        \n",
    "        # convert 2D pandas df to 3D dataframe (N,4096,12)\n",
    "        array_3d = pandas_dfs.to_numpy().reshape(int(pandas_dfs.shape[0]/4096), 4096, 12)\n",
    "\n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 0)  \n",
    "        \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        # analyze model output with thresholding\n",
    "         # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances)\n",
    "\n",
    "        # modify result \n",
    "        probability = np.insert(probability,0,normal_prob)   \n",
    "\n",
    "        # probability should be in a 2D array format\n",
    "        if probability.ndim == 1:  # Check if it's 1D\n",
    "            probability = probability.reshape(1, -1)\n",
    "        \n",
    "        return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 6)\n",
      "(827, 6)\n",
      "(827,)\n",
      "(827, 7)\n"
     ]
    }
   ],
   "source": [
    "# convert x_test from np into pandas\n",
    "hdf5_test_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "dataset_name_hdf_tracings = 'tracings'\n",
    "f = h5py.File(hdf5_test_path, \"r\")\n",
    "x_test = np.array(f[dataset_name_hdf_tracings])\n",
    "num_features = 12\n",
    "pd_test_points = ClfData.wrap_df_x(x_test, num_features)\n",
    "\n",
    "# make y_test (2D one-hot --> 1D)\n",
    "y_true_2D = pd.read_csv('/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/annotations/gold_standard.csv').values\n",
    "y_test = ClfData.wrap_df_y(y_true_2D)\n",
    "\n",
    "\n",
    "# wrap model\n",
    "classes_available = [0,1,2,3,4,5,6]\n",
    "num_columns = 4096\n",
    "wrapped_classifier = ClfModel(BasicClassifier.classifier,\n",
    "                            predict_attr=BasicClassifier.contrived_classification,\n",
    "                            predict_proba_attr=BasicClassifier.contrived_classification_proba,\n",
    "                            column_attr=pd_test_points.columns.values.tolist(),\n",
    "                            classes_attr=classes_available,\n",
    "                            window_size_attr=num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert testing dataset into \n",
    "nn_sampler = nearest_neighbor_samples(\n",
    "    clf=wrapped_classifier,\n",
    "    timeseries=pd_test_points,\n",
    "    labels=y_test,\n",
    "    silent=False,             # show log info\n",
    "    num_distractors=3,        # 3 neighbors per class\n",
    "    dont_stop=True            # unclear what this does, but included for completeness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting all samples\n",
      "making predictions for per class trees\n",
      "Validate Predictions\n",
      "0: 678\n",
      "3: 28\n",
      "1: 17\n",
      "4: 19\n",
      "6: 38\n",
      "2: 39\n",
      "5: 8\n",
      "\n",
      "True Positive Dictionary Stats\n",
      "Key: 0, Length of value: 670\n",
      "Key: 1, Length of value: 17\n",
      "Key: 2, Length of value: 28\n",
      "Key: 3, Length of value: 24\n",
      "Key: 4, Length of value: 14\n",
      "Key: 5, Length of value: 7\n",
      "Key: 6, Length of value: 35\n",
      "making per class trees\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "\n",
      "KDTree structure (underlying tree representation):\n",
      "{0: <sklearn.neighbors._kd_tree.KDTree object at 0xc23ea20>, 1: <sklearn.neighbors._kd_tree.KDTree object at 0xa910be0>, 2: <sklearn.neighbors._kd_tree.KDTree object at 0xc8132c0>, 3: <sklearn.neighbors._kd_tree.KDTree object at 0xbd19e50>, 4: <sklearn.neighbors._kd_tree.KDTree object at 0xbd179f0>, 5: <sklearn.neighbors._kd_tree.KDTree object at 0xc7f81c0>, 6: <sklearn.neighbors._kd_tree.KDTree object at 0xa93dbd0>}\n",
      "random index is 13\n",
      "random index is 18\n",
      "random index is 6\n",
      "random index is 1\n",
      "random index is 5\n",
      "random index is 6\n",
      "6\n",
      "1\n",
      "                       DI       DII      DIII       AVR       AVL       AVF  \\\n",
      "index timestamp                                                               \n",
      "463   0          0.698101  0.322306 -0.375795  0.534958 -0.027371 -0.508840   \n",
      "      1          0.700582  0.317178 -0.383404  0.542401 -0.032338 -0.508526   \n",
      "      2          0.693605  0.304881 -0.388724  0.541165 -0.038110 -0.495432   \n",
      "      3          0.691003  0.302286 -0.388717  0.539983 -0.038722 -0.492232   \n",
      "      4          0.697679  0.309640 -0.388039  0.541440 -0.037475 -0.500609   \n",
      "...                   ...       ...       ...       ...       ...       ...   \n",
      "      4091       0.624098 -0.029997 -0.654095  0.639792 -0.340845 -0.296627   \n",
      "      4092       0.628049 -0.027977 -0.656026  0.643507 -0.341710 -0.301016   \n",
      "      4093       0.632201 -0.020561 -0.652762  0.646290 -0.331286 -0.304465   \n",
      "      4094       0.632629 -0.015244 -0.647873  0.640251 -0.327748 -0.304881   \n",
      "      4095       0.637445 -0.005522 -0.642967  0.639693 -0.324668 -0.315457   \n",
      "\n",
      "                       V1        V2        V3        V4        V5        V6  \n",
      "index timestamp                                                              \n",
      "463   0         -3.281832  1.408429  2.299692  4.868410  0.661103  1.249298  \n",
      "      1         -3.273161  1.408639  2.308668  4.875765  0.651135  1.247111  \n",
      "      2         -3.277476  1.410077  2.309477  4.878103  0.647873  1.242392  \n",
      "      3         -3.271152  1.414887  2.319004  4.873635  0.654015  1.246638  \n",
      "      4         -3.258042  1.417212  2.324650  4.874226  0.652305  1.250437  \n",
      "...                   ...       ...       ...       ...       ...       ...  \n",
      "      4091       2.490827  0.320554  0.909710  1.395848  1.112608  2.180156  \n",
      "      4092       2.493899  0.322468  0.904800  1.395465  1.113488  2.176654  \n",
      "      4093       2.497935  0.328159  0.906312  1.403554  1.121957  2.177047  \n",
      "      4094       2.492406  0.320126  0.899400  1.402455  1.128061  2.172280  \n",
      "      4095       2.489372  0.311161  0.896660  1.403991  1.140922  2.177304  \n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 13\n",
      "idx for nn distractor is: 9\n",
      "2\n",
      "                  DI  DII  DIII  AVR  AVL  AVF   V1   V2   V3   V4   V5   V6\n",
      "index timestamp                                                             \n",
      "626   0          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      1          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      2          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      3          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...              ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "      4091       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4092       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4093       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4094       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4095       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 18\n",
      "idx for nn distractor is: 25\n",
      "3\n",
      "                       DI       DII      DIII       AVR       AVL       AVF  \\\n",
      "index timestamp                                                               \n",
      "185   0         -0.123227  1.641732  1.764959 -0.946156  1.698246 -0.761202   \n",
      "      1         -0.134691  1.657724  1.792415 -0.967839  1.722610 -0.761738   \n",
      "      2         -0.152441  1.669226  1.821667 -0.990865  1.745446 -0.762204   \n",
      "      3         -0.169135  1.669013  1.838148 -1.006949  1.750797 -0.751760   \n",
      "      4         -0.190672  1.666303  1.856975 -1.028654  1.757164 -0.735861   \n",
      "...                   ...       ...       ...       ...       ...       ...   \n",
      "      4091      -0.226041  1.522394  1.748436 -0.988730  1.634574 -0.647503   \n",
      "      4092      -0.234220  1.522250  1.756470 -0.993981  1.638559 -0.646659   \n",
      "      4093      -0.234116  1.524939  1.759054 -0.997741  1.637023 -0.648469   \n",
      "      4094      -0.221039  1.532029  1.753068 -0.990865  1.638738 -0.655495   \n",
      "      4095      -0.213805  1.530387  1.744192 -0.983133  1.637072 -0.661233   \n",
      "\n",
      "                       V1        V2        V3        V4        V5        V6  \n",
      "index timestamp                                                              \n",
      "185   0         -1.883964 -1.466603  0.248473 -1.520325 -1.754671 -2.167583  \n",
      "      1         -1.877455 -1.447693  0.276324 -1.501583 -1.738876 -2.159820  \n",
      "      2         -1.867399 -1.432943  0.297259 -1.486297 -1.730202 -2.157036  \n",
      "      3         -1.861034 -1.420690  0.312521 -1.468302 -1.718848 -2.157837  \n",
      "      4         -1.846991 -1.405357  0.339822 -1.448848 -1.700514 -2.143486  \n",
      "...                   ...       ...       ...       ...       ...       ...  \n",
      "      4091      -1.423182 -0.971732 -0.387246 -0.863680 -1.166790 -1.827933  \n",
      "      4092      -1.427591 -0.962207 -0.368671 -0.856425 -1.162433 -1.827067  \n",
      "      4093      -1.432896 -0.957192 -0.352493 -0.850316 -1.153832 -1.828512  \n",
      "      4094      -1.432943 -0.945133 -0.335370 -0.838424 -1.143305 -1.829289  \n",
      "      4095      -1.431003 -0.931898 -0.317943 -0.825344 -1.137071 -1.821809  \n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 6\n",
      "idx for nn distractor is: 9\n",
      "4\n",
      "                  DI  DII  DIII  AVR  AVL  AVF   V1   V2   V3   V4   V5   V6\n",
      "index timestamp                                                             \n",
      "75    0          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      1          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      2          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      3          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...              ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "      4091       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4092       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4093       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4094       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4095       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 1\n",
      "idx for nn distractor is: 11\n",
      "5\n",
      "                  DI  DII  DIII  AVR  AVL  AVF   V1   V2   V3   V4   V5   V6\n",
      "index timestamp                                                             \n",
      "564   0          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      1          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      2          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      3          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...              ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "      4091       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4092       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4093       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4094       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4095       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 5\n",
      "idx for nn distractor is: 6\n",
      "6\n",
      "                  DI  DII  DIII  AVR  AVL  AVF   V1   V2   V3   V4   V5   V6\n",
      "index timestamp                                                             \n",
      "137   0          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      1          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      2          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      3          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4          0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "...              ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "      4091       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4092       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4093       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4094       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "      4095       0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[4096 rows x 12 columns]\n",
      "idx for nn distractor is: 6\n",
      "idx for nn distractor is: 0\n"
     ]
    }
   ],
   "source": [
    "samples = nn_sampler.get_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "\n",
      "Class ID: 1\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "\n",
      "Class ID: 2\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "\n",
      "Class ID: 3\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "\n",
      "Class ID: 4\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "\n",
      "Class ID: 5\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "\n",
      "Class ID: 6\n",
      "Number of items: 3\n",
      "  Item 0: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 1: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n",
      "  Item 2: type = <class 'pandas.core.frame.DataFrame'>\n",
      "    shape = (4096, 12)\n"
     ]
    }
   ],
   "source": [
    "print(len(samples))\n",
    "#print((samples))\n",
    "\n",
    "for class_id, items in samples.items():\n",
    "    print(f\"\\nClass ID: {class_id}\")\n",
    "    print(f\"Number of items: {len(items)}\")\n",
    "    for i, (cls, data) in enumerate(items):\n",
    "        print(f\"  Item {i}: type = {type(data)}\")\n",
    "        if hasattr(data, \"shape\"):\n",
    "            print(f\"    shape = {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Lipschiz Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructor for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n",
      "(20000, 6)\n",
      "(20000,)\n",
      "(20000, 7)\n"
     ]
    }
   ],
   "source": [
    "# for CoMTE\n",
    "sys.path.append('/projectnb/peaclab-mon/JLi/projectx/CoMTE_V2_JLi/CoMTE_V2/comlex_core/src')  # Path to the comlex_core directory\n",
    "import explainers as explainers_V2\n",
    "import itertools\n",
    "\n",
    "class BasicData:\n",
    "    # define basic variables\n",
    "    classes_available = [0,1,2,3,4,5,6]\n",
    "    num_columns = 4096\n",
    "    num_features = 12\n",
    "\n",
    "    # define paths and variables for training data\n",
    "    path_to_hdf5_test = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "    dataset_name_hdf_tracings = \"tracings\" \n",
    "    training_set_hdf_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/combined_V2.hdf5\"\n",
    "    y_train_csv_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/labels_combined_V2.csv\"\n",
    "    \n",
    "    f = h5py.File(training_set_hdf_path, \"r\")\n",
    "    timeseries = np.array(f[dataset_name_hdf_tracings])\n",
    "\n",
    "    # iterable of corresponding labels for the samples for the data wrapper (returns 20000x6 np array) <--- take out first column that represents ExamID\n",
    "    labels = pd.read_csv(y_train_csv_path)\n",
    "\n",
    "\n",
    "class BasicComlexInput:\n",
    "\n",
    "    # 1. wrap training points\n",
    "    df_train_points = ClfData.wrap_df_x(BasicData.timeseries, BasicData.num_features)\n",
    "    \n",
    "    # 2. wrap training labels\n",
    "    df_train_labels = ClfData.wrap_df_y(BasicData.labels)\n",
    "\n",
    "    # 3. wrap up the classifier\n",
    "    # note: column_attr, or the corresponding name of the columns in the sample,\n",
    "    #  is unique to dataframes, and auto-generated by wrap_df_x\n",
    "    # wrapped_classifier = ClfModel(BasicClassifier.classifier,\n",
    "    #                             predict_attr=BasicClassifier.contrived_classification,\n",
    "    #                             predict_proba_attr=BasicClassifier.contrived_classification_proba,\n",
    "    #                             column_attr=df_train_points.columns.values.tolist(),\n",
    "    #                             classes_attr=BasicData.classes_available,\n",
    "    #                             window_size_attr=BasicData.num_columns)    \n",
    "    \n",
    "    # get testing point\n",
    "    test_point = seq._getsample_(253)\n",
    "    # wrap test point \n",
    "    test_df = ClfData.wrap_df_test_point(test_point)\n",
    "\n",
    "\n",
    "# set up an optimized search comlex runner\n",
    "# note: classifier was set up above\n",
    "comlex = explainers_V2.OptimizedSearch(wrapped_classifier,\n",
    "                                    BasicComlexInput.df_train_points,\n",
    "                                    BasicComlexInput.df_train_labels,\n",
    "                                    silent=True, threads=4, num_distractors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 1\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      "  1.2989482e-02 3.3653807e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "Distractor 2 probability: \n",
      "[[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "Distractor 3 probability: \n",
      "[[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.9171523  0.5594475  0.0015257  0.00094964 0.00123623 0.01701298\n",
      " 0.00107937]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.4367379e-01 4.2005047e-01 1.5444350e-03 3.1178986e-04 2.3657065e-03\n",
      "  3.5973813e-03 4.1675910e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[0.9997933  0.12508635 0.01220329 0.0049306  0.00384609 0.06215671\n",
      "  0.00247893]]\n",
      "Distractor 2 probability: \n",
      "[[9.3736696e-01 4.5319939e-01 2.7376760e-04 7.7905643e-05 1.9336505e-04\n",
      "  2.0425257e-03 3.5571277e-06]]\n",
      "Distractor 3 probability: \n",
      "[[9.3292719e-01 4.7653469e-01 6.8660593e-05 8.8669207e-05 2.2072965e-04\n",
      "  2.7876055e-01 1.9830064e-04]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[0.9997933  0.12508635 0.01220329 0.0049306  0.00384609 0.06215671\n",
      "  0.00247893]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.4367379e-01 4.2005047e-01 1.5444350e-03 3.1178986e-04 2.3657065e-03\n",
      " 3.5973813e-03 4.1675910e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.3736696e-01 4.5319939e-01 2.7376760e-04 7.7905643e-05 1.9336505e-04\n",
      "  2.0425257e-03 3.5571277e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVF')}\n",
      "pruned sample probabilities are [9.3281776e-01 4.7710985e-01 1.2627032e-03 2.7888184e-04 1.5035592e-03\n",
      " 4.4419058e-03 4.8703339e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[9.3292719e-01 4.7653469e-01 6.8660593e-05 8.8669207e-05 2.2072965e-04\n",
      "  2.7876055e-01 1.9830064e-04]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [9.3402666e-01 4.7075593e-01 1.7014691e-03 2.9734976e-04 1.9599658e-03\n",
      " 3.9317249e-03 1.9197356e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      "  1.2989482e-02 3.3653807e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "Distractor 2 probability: \n",
      "[[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "Distractor 3 probability: \n",
      "[[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.9171523  0.5594475  0.0015257  0.00094964 0.00123623 0.01701298\n",
      " 0.00107937]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      "  1.2989482e-02 3.3653807e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "Distractor 2 probability: \n",
      "[[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "Distractor 3 probability: \n",
      "[[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.9171523  0.5594475  0.0015257  0.00094964 0.00123623 0.01701298\n",
      " 0.00107937]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.4367379e-01 4.2005047e-01 1.5444350e-03 3.1178986e-04 2.3657065e-03\n",
      "  3.5973813e-03 4.1675910e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[0.9997933  0.12508635 0.01220329 0.0049306  0.00384609 0.06215671\n",
      "  0.00247893]]\n",
      "Distractor 2 probability: \n",
      "[[9.3736696e-01 4.5319939e-01 2.7376760e-04 7.7905643e-05 1.9336505e-04\n",
      "  2.0425257e-03 3.5571277e-06]]\n",
      "Distractor 3 probability: \n",
      "[[9.3292719e-01 4.7653469e-01 6.8660593e-05 8.8669207e-05 2.2072965e-04\n",
      "  2.7876055e-01 1.9830064e-04]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[0.9997933  0.12508635 0.01220329 0.0049306  0.00384609 0.06215671\n",
      "  0.00247893]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.4367379e-01 4.2005047e-01 1.5444350e-03 3.1178986e-04 2.3657065e-03\n",
      " 3.5973813e-03 4.1675910e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.3736696e-01 4.5319939e-01 2.7376760e-04 7.7905643e-05 1.9336505e-04\n",
      "  2.0425257e-03 3.5571277e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVF')}\n",
      "pruned sample probabilities are [9.3281776e-01 4.7710985e-01 1.2627032e-03 2.7888184e-04 1.5035592e-03\n",
      " 4.4419058e-03 4.8703339e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[9.3292719e-01 4.7653469e-01 6.8660593e-05 8.8669207e-05 2.2072965e-04\n",
      "  2.7876055e-01 1.9830064e-04]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [9.3402666e-01 4.7075593e-01 1.7014691e-03 2.9734976e-04 1.9599658e-03\n",
      " 3.9317249e-03 1.9197356e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(1)] \n",
      "Sample Probabilities: [[9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      "  1.2989482e-02 3.3653807e-05]]\n",
      "Class of Interest: 1\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "Distractor 2 probability: \n",
      "[[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "Distractor 3 probability: \n",
      "[[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.9172411e-01 6.9309807e-01 4.8672420e-05 2.2062271e-05 2.3005109e-06\n",
      "  1.5616019e-02 4.7103786e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.1059238e-01 5.9392655e-01 1.8268339e-03 1.4687905e-02 2.9223080e-04\n",
      "  5.6689147e-02 8.1678838e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.9171523  0.5594475  0.0015257  0.00094964 0.00123623 0.01701298\n",
      " 0.00107937]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.6975950e-01 8.0854422e-01 3.8052210e-06 6.6586483e-07 8.2461199e-08\n",
      "  2.7381795e-05 1.6021142e-09]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [9.2682105e-01 5.0862855e-01 2.4123222e-03 6.3755880e-03 5.7806697e-04\n",
      " 1.2989482e-02 3.3653807e-05]\n",
      "pruned sample class is 1\n",
      "to_max is 1\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVR'), np.str_('AVL')}\n",
      "Class: 2\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      "  1.4694318e-02 9.3513847e-07]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      " 1.4694318e-02 9.3513847e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6657876e-01 1.2782522e-01 8.1042951e-01 1.9512301e-02 2.7328408e-01\n",
      " 1.9629091e-02 8.9748977e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6668223e-01 1.0157076e-01 8.1391317e-01 1.7734455e-02 2.6660633e-01\n",
      " 1.2731887e-02 5.0068559e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[9.0025252e-01 3.1399820e-04 6.2659097e-01 7.6922104e-03 2.6735275e-05\n",
      "  1.9817103e-03 5.2908719e-05]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.8649482e-01 9.2717685e-04 7.0335901e-01 7.7321390e-03 2.7192953e-05\n",
      " 5.1712967e-03 7.4324875e-05]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.9120066e-01 1.2857891e-03 6.7710042e-01 7.2598322e-03 3.7281123e-05\n",
      " 5.9701395e-03 1.5692743e-04]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.9287478e-01 1.4986676e-03 6.6775870e-01 1.5163556e-02 3.6622740e-05\n",
      " 7.9480726e-03 1.1665864e-04]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      "  1.4694318e-02 9.3513847e-07]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      " 1.4694318e-02 9.3513847e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6657876e-01 1.2782522e-01 8.1042951e-01 1.9512301e-02 2.7328408e-01\n",
      " 1.9629091e-02 8.9748977e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6668223e-01 1.0157076e-01 8.1391317e-01 1.7734455e-02 2.6660633e-01\n",
      " 1.2731887e-02 5.0068559e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      "  1.4694318e-02 9.3513847e-07]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      " 1.4694318e-02 9.3513847e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6657876e-01 1.2782522e-01 8.1042951e-01 1.9512301e-02 2.7328408e-01\n",
      " 1.9629091e-02 8.9748977e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6668223e-01 1.0157076e-01 8.1391317e-01 1.7734455e-02 2.6660633e-01\n",
      " 1.2731887e-02 5.0068559e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[9.0025252e-01 3.1399820e-04 6.2659097e-01 7.6922104e-03 2.6735275e-05\n",
      "  1.9817103e-03 5.2908719e-05]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.8649482e-01 9.2717685e-04 7.0335901e-01 7.7321390e-03 2.7192953e-05\n",
      " 5.1712967e-03 7.4324875e-05]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.9120066e-01 1.2857891e-03 6.7710042e-01 7.2598322e-03 3.7281123e-05\n",
      " 5.9701395e-03 1.5692743e-04]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.9287478e-01 1.4986676e-03 6.6775870e-01 1.5163556e-02 3.6622740e-05\n",
      " 7.9480726e-03 1.1665864e-04]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(2)] \n",
      "Sample Probabilities: [[8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      "  1.4694318e-02 9.3513847e-07]]\n",
      "Class of Interest: 2\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "Distractor 3 probability: \n",
      "[[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.8647002e-01 6.0576241e-04 7.0349723e-01 7.3928369e-04 1.5805702e-04\n",
      "  4.0880215e-04 1.1089243e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6331534e-01 1.1454554e-01 8.0998164e-01 1.9672632e-02 2.9563746e-01\n",
      " 1.4694318e-02 9.3513847e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.5736603e-01 7.0394628e-04 8.6589742e-01 7.0307066e-04 3.4449949e-06\n",
      "  6.4907782e-04 7.3148033e-07]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6657876e-01 1.2782522e-01 8.1042951e-01 1.9512301e-02 2.7328408e-01\n",
      " 1.9629091e-02 8.9748977e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5787344e-01 2.9515969e-03 8.6306626e-01 8.8919317e-03 2.6115340e-01\n",
      "  2.5786737e-03 5.5889775e-08]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6668223e-01 1.0157076e-01 8.1391317e-01 1.7734455e-02 2.6660633e-01\n",
      " 1.2731887e-02 5.0068559e-07]\n",
      "pruned sample class is 2\n",
      "to_max is 2\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVF')}\n",
      "Class: 3\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(3)] \n",
      "Sample Probabilities: [[8.6780798e-01 8.4342156e-04 1.3630447e-04 8.0349445e-01 1.1284837e-05\n",
      "  7.8477972e-04 1.2158698e-04]]\n",
      "Class of Interest: 3\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "Distractor 3 probability: \n",
      "[[8.5534006e-01 2.5598055e-03 2.7697813e-03 8.7456149e-01 7.4675423e-03\n",
      "  2.2759105e-04 1.3273956e-05]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR')}\n",
      "pruned explanation is {np.str_('AVR')}\n",
      "pruned sample probabilities are [8.6523026e-01 1.4827979e-03 1.4457259e-04 8.1818759e-01 1.3915355e-05\n",
      " 1.6306513e-03 1.7144972e-04]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6780798e-01 8.4342156e-04 1.3630447e-04 8.0349445e-01 1.1284837e-05\n",
      " 7.8477972e-04 1.2158698e-04]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5534006e-01 2.5598055e-03 2.7697813e-03 8.7456149e-01 7.4675423e-03\n",
      "  2.2759105e-04 1.3273956e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVL'), np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVL'), np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6107165e-01 8.9070533e-04 1.6604892e-04 8.4189171e-01 8.8458492e-06\n",
      " 8.0436794e-04 5.2789728e-05]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVL'), np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(3)] \n",
      "Sample Probabilities: [[9.0364850e-01 1.7087391e-01 2.5014551e-03 5.4837012e-01 1.7168712e-03\n",
      "  2.2591704e-01 8.8277453e-04]]\n",
      "Class of Interest: 3\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[8.5405898e-01 1.0430407e-03 3.1251155e-04 8.8186389e-01 1.3964099e-04\n",
      "  7.6572789e-04 1.7798027e-05]]\n",
      "Distractor 2 probability: \n",
      "[[9.9825281e-01 6.6284345e-05 1.9625200e-02 5.9958994e-02 4.3090172e-03\n",
      "  1.2990218e-04 3.7029691e-05]]\n",
      "Distractor 3 probability: \n",
      "[[9.7020632e-01 2.8292704e-02 2.5330044e-03 2.1982408e-01 8.4608346e-03\n",
      "  1.5290683e-03 2.0385065e-04]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[8.5405898e-01 1.0430407e-03 3.1251155e-04 8.8186389e-01 1.3964099e-04\n",
      "  7.6572789e-04 1.7798027e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [8.9416957e-01 1.6713014e-01 1.2905039e-03 6.0645974e-01 7.4471417e-04\n",
      " 1.6421576e-01 1.2176381e-03]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[9.9825281e-01 6.6284345e-05 1.9625200e-02 5.9958994e-02 4.3090172e-03\n",
      "  1.2990218e-04 3.7029691e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.8974978  0.14817299 0.00261803 0.6080476  0.00094704 0.27977008\n",
      " 0.00174873]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[9.7020632e-01 2.8292704e-02 2.5330044e-03 2.1982408e-01 8.4608346e-03\n",
      "  1.5290683e-03 2.0385065e-04]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned explanation is {np.str_('AVR'), np.str_('AVL')}\n",
      "pruned sample probabilities are [0.89432716 0.16898535 0.00173685 0.6035497  0.00094683 0.16874997\n",
      " 0.00111401]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('V2'), np.str_('AVR'), np.str_('AVL')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(3)] \n",
      "Sample Probabilities: [[8.6780798e-01 8.4342156e-04 1.3630447e-04 8.0349445e-01 1.1284837e-05\n",
      "  7.8477972e-04 1.2158698e-04]]\n",
      "Class of Interest: 3\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "Distractor 3 probability: \n",
      "[[8.5534006e-01 2.5598055e-03 2.7697813e-03 8.7456149e-01 7.4675423e-03\n",
      "  2.2759105e-04 1.3273956e-05]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR')}\n",
      "pruned explanation is {np.str_('AVR')}\n",
      "pruned sample probabilities are [8.6523026e-01 1.4827979e-03 1.4457259e-04 8.1818759e-01 1.3915355e-05\n",
      " 1.6306513e-03 1.7144972e-04]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is set()\n",
      "pruned explanation is set()\n",
      "pruned sample probabilities are [8.6780798e-01 8.4342156e-04 1.3630447e-04 8.0349445e-01 1.1284837e-05\n",
      " 7.8477972e-04 1.2158698e-04]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 3 of 3\n",
      "Probabilities of distractor sample: [[8.5534006e-01 2.5598055e-03 2.7697813e-03 8.7456149e-01 7.4675423e-03\n",
      "  2.2759105e-04 1.3273956e-05]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVL'), np.str_('AVF')}\n",
      "pruned explanation is {np.str_('AVL'), np.str_('AVF')}\n",
      "pruned sample probabilities are [8.6107165e-01 8.9070533e-04 1.6604892e-04 8.4189171e-01 8.8458492e-06\n",
      " 8.0436794e-04 5.2789728e-05]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "algorithm completed with optimized search\n",
      "best_explanation is: {np.str_('AVL'), np.str_('AVF')}\n",
      "-------Preliminary Statistics-------\n",
      "Original Sample Class: [np.int64(3)] \n",
      "Sample Probabilities: [[8.6780798e-01 8.4342156e-04 1.3630447e-04 8.0349445e-01 1.1284837e-05\n",
      "  7.8477972e-04 1.2158698e-04]]\n",
      "Class of Interest: 3\n",
      "\n",
      "\n",
      "generating distractors\n",
      "Class 0 has 16498 indices.\n",
      "Class 1 has 227 indices.\n",
      "Class 2 has 449 indices.\n",
      "Class 3 has 264 indices.\n",
      "Class 4 has 258 indices.\n",
      "Class 5 has 246 indices.\n",
      "Class 6 has 390 indices.\n",
      "validate distractors probabilities:\n",
      "Distractor 1 probability: \n",
      "[[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "Distractor 2 probability: \n",
      "[[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "Distractor 3 probability: \n",
      "[[8.5534006e-01 2.5598055e-03 2.7697813e-03 8.7456149e-01 7.4675423e-03\n",
      "  2.2759105e-04 1.3273956e-05]]\n",
      "\n",
      "processing distractor 1 of 3\n",
      "Probabilities of distractor sample: [[9.1880262e-01 2.2484385e-04 5.3408643e-04 5.1282495e-01 4.4161885e-07\n",
      "  3.4711000e-05 6.1722822e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n",
      "mlrose result result is:[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "pruning\n",
      "pruning output is {np.str_('AVR')}\n",
      "pruned explanation is {np.str_('AVR')}\n",
      "pruned sample probabilities are [8.6523026e-01 1.4827979e-03 1.4457259e-04 8.1818759e-01 1.3915355e-05\n",
      " 1.6306513e-03 1.7144972e-04]\n",
      "pruned sample class is 3\n",
      "to_max is 3\n",
      "True\n",
      "\n",
      "processing distractor 2 of 3\n",
      "Probabilities of distractor sample: [[8.4929240e-01 3.5473381e-04 9.6033135e-04 9.0903318e-01 8.2916796e-04\n",
      "  7.9790101e-05 3.2203752e-06]]\n",
      "mlrose starting\n",
      "\n",
      "\n",
      "-------Running Discrete Optimization Algorithm for Feature Selection------\n"
     ]
    }
   ],
   "source": [
    "# Loop over the dictionary\n",
    "\n",
    "results_df = pd.DataFrame(columns=['class', 'node_id', 'pair_index', 'dist', 'lipschitz'])\n",
    "\n",
    "for key, tuple_list in samples.items():\n",
    "    print(f\"Class: {key}\")\n",
    "    \n",
    "    # Get all 2-tuple combinations\n",
    "    for t1, t2 in itertools.combinations(tuple_list, 2):\n",
    "        # calculate euclidenan distance between samples\n",
    "        # Flatten both DataFrames\n",
    "        vec1 = t1[1].values.flatten()\n",
    "        vec2 = t2[1].values.flatten()\n",
    "\n",
    "        # get explanations\n",
    "        explanation_t1 = comlex.explain(t1[1],to_maximize=key,\n",
    "                             return_dist=True,single=True,\n",
    "                             savefig=True,train_iter=100,\n",
    "                             timeseries=False,filename=\"sample_result.png\")\n",
    "        explanation_t2 = comlex.explain(t2[1],to_maximize=key,\n",
    "                             return_dist=True,single=True,\n",
    "                             savefig=True,train_iter=100,\n",
    "                             timeseries=False,filename=\"sample_result.png\")\n",
    "        \n",
    "        # convert into sets for set distance\n",
    "        exp_t1_set = set(explanation_t1[1].values.flatten())  \n",
    "        exp_t2_set = set(explanation_t2[1].values.flatten())  \n",
    "        # calculate set distance between explanations\n",
    "        exp_diff = len(exp_t1_set.difference(exp_t2_set)) + len(exp_t2_set.difference(exp_t1_set))\n",
    "        \n",
    "        # Compute Euclidean distance between samples\n",
    "        clf_diff = np.linalg.norm(vec1 - vec2)\n",
    "        \n",
    "        # calculate lipschiz ratio\n",
    "        lipschitz = -1 * exp_diff / clf_diff\n",
    "\n",
    "        # Store results in the DataFrame\n",
    "        new_row = pd.DataFrame({\n",
    "            'class': [key],\n",
    "            'node_id': [t1[0]],  # Or other relevant identifiers\n",
    "            'pair_index': [idx],\n",
    "            'dist': [dist],\n",
    "            'lipschitz': [lipschitz]\n",
    "        })\n",
    "        results_df = pd.concat([results_df,new_row],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "import shap\n",
    "\n",
    "\"\"\"\n",
    "SHAP Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "class BasicSHAPInput:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "    # wrap training points for SHAP\n",
    "    df_train_points_SHAP = ClfData.wrap_df_x_SHAP(BasicData.timeseries, BasicData.num_features)\n",
    "\n",
    "    # select test point \n",
    "    test_point = seq._getsample_(253)\n",
    "    \n",
    "    # wrap test point for SHAP\n",
    "    test_df_SHAP = ClfData.wrap_df_test_point_SHAP(test_point)\n",
    "\n",
    "class BasicSHAPClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "# X_train_background is typically a small representative subset of X_train\n",
    "BasicSHAPInput.df_train_points_SHAP.shape\n",
    "\n",
    "# init explainer\n",
    "explainer = shap.GradientExplainer(BasicSHAPClassifier.classifier, BasicSHAPInput.df_train_points_SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "\n",
    "shap_values = explainer.shap_values(BasicSHAPInput.test_df_SHAP)\n",
    "print(shap_values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LIME Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SHAP Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "class BasicLIMEClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "    import os\n",
    "    @staticmethod\n",
    "    def contrived_classification(pandas_dfs):\n",
    "        \"\"\"\n",
    "        Notes: \n",
    "            if there were multiple classes that exceeded the threshold, the class with the highest exceedance was assigned\n",
    "            to the sample\n",
    "\n",
    "        Input: \n",
    "            numpy_df: pandas multiindex array of samples\n",
    "\n",
    "        Output: \n",
    "            if there is one sample: function returns the index\n",
    "            if there are multiple samples: function returns a (1xN) list of the indices\n",
    "        \"\"\"\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "        \n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 1)    \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "        # analyze model output with thresholding\n",
    "        # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        \n",
    "        # Add normal_prob as a new column\n",
    "        probability_n = np.column_stack((normal_prob, probability))     \n",
    "\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        mask = probability_n >= new_threshold\n",
    "        sample_classes = []\n",
    "        \n",
    "        for row, mask in zip(probability_n, mask):\n",
    "            passing_indices = np.where(mask)[0]\n",
    "            if len(passing_indices) > 1:  # If more than one indices pass\n",
    "                # compute exceedance\n",
    "                exceedances = row[passing_indices] - new_threshold[passing_indices]\n",
    "                # Get class with the highest exceedance\n",
    "                max_class = passing_indices[np.argmax(exceedances)]\n",
    "                sample_classes.append(max_class)\n",
    "            elif len(passing_indices) == 0:  # no passes\n",
    "                sample_classes.append(0) \n",
    "            else:\n",
    "                sample_classes.append(passing_indices[0])  \n",
    "                \n",
    "        # don't return list if only one sample\n",
    "        if len(sample_classes) == 1:\n",
    "            sample_classes = sample_classes[0]\n",
    "        \n",
    "        return sample_classes \n",
    "    \n",
    "    # LIME prediction function...\n",
    "    def contrived_classification_proba_LIME(np_2d_array):\n",
    "        import os\n",
    "        \"\"\"\n",
    "        Purpose: \n",
    "            make prediction and return set of probabilities\n",
    "        Return: \n",
    "            if there are single or multiple samples: function returns a list of arrays containing the probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        # reshape\n",
    "        num_features = np_2d_array.shape[0]\n",
    "        print(f\"num features is {num_features}\")\n",
    "        df_reshaped = np_2d_array.reshape(num_features, 4096, 12)\n",
    "\n",
    "        # init classifier\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(df_reshaped, verbose = 1)  \n",
    "        \n",
    "        return probability\n",
    "        \n",
    "class BasicLIMEInput:\n",
    "    classifier = pre_model  # tensorflow CNN    \n",
    "\n",
    "    # wrap training points for LIME\n",
    "    df_train_points_LIME = ClfData.wrap_df_x_LIME(BasicData.timeseries, BasicData.num_features)\n",
    "    \n",
    "    # wrap training labels \n",
    "    df_train_labels = ClfData.wrap_df_y(BasicData.labels)\n",
    "    \n",
    "    # select test point \n",
    "    test_point = seq._getsample_(253)\n",
    "\n",
    "    # wrap test point for LIME\n",
    "    test_df_LIME = ClfData.wrap_df_test_point_LIME(test_point)\n",
    "\n",
    "\n",
    "    # wrap classifier for LIME\n",
    "    wrapped_classifier_LIME = ClfModel(BasicLIMEClassifier.classifier,\n",
    "                                predict_attr=BasicLIMEClassifier.contrived_classification,\n",
    "                                predict_proba_attr=BasicLIMEClassifier.contrived_classification_proba_LIME,\n",
    "                                column_attr=['DI','DII','DIII','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6'],\n",
    "                                classes_attr=BasicData.classes_available,\n",
    "                                window_size_attr=BasicData.num_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import lime.lime_tabular as limetabular\n",
    "\n",
    "# instantiate LIME tabular explainer\n",
    "'''\n",
    "    input: \n",
    "    1. flattened data (N,49152) <-- flattened in row-major order (C-style)\n",
    "    2. model\n",
    "    3. feature names \n",
    "    4. classification\n",
    "'''\n",
    "LIME_explainer = limetabular.LimeTabularExplainer(BasicLIMEInput.df_train_points_LIME, \n",
    "                                                  mode = 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.DEBUG)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries, labels, test_timeseries, test_labels = data_loading.load_hpc_data(\n",
    "    # Path('/home/ates/data/taxonomist/'), window=60, skip=60, make_binary=True)\n",
    "    Path('/projectnb/peaclab-mon/ates/hpas'), classes=['memorybandwidth', 'none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "!pip install scikit-learn==0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_kwargs = []\n",
    "for p in ['l1', 'l2', 'elasticnet', 'none']:\n",
    "    for tol in np.logspace(-8, -1, 8):\n",
    "        for solver in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "            for c in np.logspace(-8, 8, 20) if p != 'none' else [1]:\n",
    "                kwargs = {'penalty': p, 'tol': tol, 'C': c, 'solver': solver, 'fit_intercept': False}\n",
    "                try:\n",
    "                    clf = LogisticRegression(**kwargs)\n",
    "                    clf.fit([[1], [0]], [1, 0])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                else:\n",
    "                    good_kwargs.append(kwargs)\n",
    "print(len(good_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_kwargs = []\n",
    "pipelines = []\n",
    "scores = []\n",
    "random.shuffle(good_kwargs)\n",
    "\n",
    "\n",
    "# pull out feature extraction\n",
    "\n",
    "\n",
    "for kwargs in tqdm(good_kwargs):\n",
    "    \n",
    "    p = Pipeline([\n",
    "        ('assert1', analysis.classifier.CheckFeatures()),\n",
    "        ('features', analysis.data.TSFeatureGenerator(threads=1, trim=0)),\n",
    "        ('assert2', analysis.classifier.CheckFeatures()),\n",
    "        ('scaler', MinMaxScaler(feature_range=(-1, 1))),\n",
    "        ('clf', LogisticRegression(**kwargs))\n",
    "    ])\n",
    "\n",
    "    p.fit(timeseries, np.ravel(labels))\n",
    "    preds = p.predict(test_timeseries)\n",
    "    score = f1_score(test_labels, preds, average='weighted')\n",
    "    \n",
    "    to_add = False\n",
    "    if score > 0.975:\n",
    "        to_add = True\n",
    "        for p2 in pipelines:\n",
    "            if np.linalg.norm(p.steps[4][1].coef_ - p2.steps[4][1].coef_) == 0:\n",
    "                to_add = False\n",
    "    if not to_add:\n",
    "        continue\n",
    "    scores.append(score)\n",
    "    pipelines.append(p)\n",
    "    used_kwargs.append(kwargs)\n",
    "    if len(pipelines) >= 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_constructors = {\n",
    "    'lime': explainers.LimeExplanation,\n",
    "    'random': explainers.RandomExplanation,\n",
    "    'shap': explainers.ShapExplanation,\n",
    "    'our_method': explainers.BruteForceSearch,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for node_id in tqdm(random.sample(list(test_timeseries.index.get_level_values('node_id').unique()), 50)):\n",
    "    x_test = test_timeseries.loc[[node_id], :, :]\n",
    "    for e in explainer_constructors:\n",
    "        explanations = []\n",
    "        for p in pipelines:\n",
    "            exp = explainer_constructors[e](p, timeseries, labels)\n",
    "            explanations.append(set(exp.explain(x_test)))\n",
    "        min_ratio = 0\n",
    "        for clf1 in range(len(pipelines)):\n",
    "            for clf2 in range(clf1):\n",
    "                clf_diff = np.linalg.norm(pipelines[clf1].steps[4][1].coef_ - pipelines[clf2].steps[4][1].coef_)\n",
    "                print(pipelines[clf1].steps[4][1])\n",
    "                print(pipelines[clf2].steps[4][1])\n",
    "                \n",
    "                exp_diff = len(explanations[clf1].difference(explanations[clf2])) + len(explanations[clf2].difference(explanations[clf1]))\n",
    "                lipschitz = -1 * exp_diff / clf_diff\n",
    "                if lipschitz < min_ratio:\n",
    "                    min_ratio = lipschitz\n",
    "        results.append({\n",
    "            'method': e,\n",
    "            'node_id': node_id,\n",
    "            'ratio': min_ratio,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lipschitz'] = df['ratio'].apply(lambda x: - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df, x='method', y='lipschitz', kind='box', order=['our_method', 'lime', 'shap', 'random'])#, showfliers=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
