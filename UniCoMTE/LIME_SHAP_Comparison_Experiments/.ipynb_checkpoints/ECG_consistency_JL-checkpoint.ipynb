{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistency: Are the explanations consistent for similar classifiers?\n",
    "\n",
    "* Train many logistic regression classifiers with different hyperparameters\n",
    "* Get explanations for each sample in the test set and each classifier\n",
    "* Report Lipschitz estimate for explanations of each classifier\n",
    "\n",
    "Methodology for Sample Selection:\n",
    "* For each class, randomly select one sample. Then, select 2 additional true positive samples of that class with the smallest euclidenan distance to the initial sample chosen.\n",
    "\n",
    "\n",
    "Data Formats Before Wrappers: \n",
    "* Timeseries: 3D numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 23:05:45.611220: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 23:05:46.662242: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 23:05:47.149141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744254347.895974 3384280 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744254347.996452 3384280 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "from multiprocessing import Pool\n",
    "import functools\n",
    "import sys \n",
    "import random\n",
    "from pathlib import Path\n",
    "import time\n",
    "import mlrose_ky as mlrose\n",
    "#import mlrose\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ecg_analysis.data \n",
    "import ecg_analysis.classifier\n",
    "import explainers_benchmarking as explainers\n",
    "\n",
    "import datasets\n",
    "\n",
    "from explainable_model_ECG import ClfModel as ClfModel\n",
    "from explainable_data_ECG import ClfData as ClfData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load in Testing Data, Select Samples of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 23:06:21.946334: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step\n",
      "(827, 6)\n",
      "[[1.4243224e-06 1.0710056e-07 2.6337096e-07 4.5377533e-07 9.4853954e-07\n",
      "  6.4135262e-09]\n",
      " [2.8897326e-02 2.0066644e-03 3.1778643e-01 2.8277413e-05 4.8343580e-02\n",
      "  3.2050046e-04]\n",
      " [3.1124635e-04 2.9402861e-05 4.1752328e-06 1.9712761e-05 9.3489764e-03\n",
      "  2.4932469e-05]\n",
      " [2.3969020e-09 1.7344874e-09 6.9393408e-10 8.1738605e-10 5.6821232e-09\n",
      "  2.7672534e-10]\n",
      " [5.3062366e-04 3.5334501e-06 3.3941697e-07 1.4301370e-06 2.2422858e-04\n",
      "  4.7077383e-06]]\n",
      "Output predictions saved\n",
      "(None, 4096, 12)\n"
     ]
    }
   ],
   "source": [
    "# load in ECG Testing Set\n",
    "\n",
    "# Select points to explain from testing set\n",
    "\n",
    "# load testing dataset \n",
    "path_to_hdf5_test = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "dataset_name_test = \"tracings\"  \n",
    "\n",
    "# Import data. SEQ is an instance of class ECGSequence\n",
    "seq = datasets.ECGSequence(path_to_hdf5_test, dataset_name_test)  # using default batch size\n",
    "\n",
    "# load pretrained model (still need to compile later) \n",
    "model_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/PretrainedModels/model/model.hdf5\"\n",
    "pre_model = load_model(model_path)  \n",
    "\n",
    "# compile and apply model to testing dataset\n",
    "pre_model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "model_predictions = pre_model.predict(seq,verbose=1)   # y_score is a numpy array with dimensions 827x6. It holds the predictions generated by the model\n",
    "\n",
    "# extra\n",
    "print(model_predictions.shape)\n",
    "print(model_predictions[:5])\n",
    "\n",
    "# Generate dataframe\n",
    "np.save(\"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/dnn_output.npy\", model_predictions)\n",
    "print(\"Output predictions saved\")\n",
    "\n",
    "print(pre_model.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ECG_one_d_labels(model_predictions, onehot_labels = True):\n",
    "    '''\n",
    "    \n",
    "    Purpose: turn one-hot encoding (N,d) array into (Nx1) vector of classes\n",
    "\n",
    "    Input: \n",
    "    model_predictions: 2D array of probabilities or one-hot encodings (827x6)\n",
    "    onehot_labels: boolean variable \n",
    "\n",
    "    Output: \n",
    "    (Nx1) vector of classes\n",
    "\n",
    "    Comments: \n",
    "    The sample class is the class that exceeds the threshold\n",
    "    If there are >1 classes that exceed the threshold, a tuple will be used to store the multiple classes \n",
    "    '''\n",
    "    \n",
    "\n",
    "    if not onehot_labels:\n",
    "        # establish threshold\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((model_predictions - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        # add normal prob\n",
    "        probability_n = np.column_stack((normal_prob, model_predictions))\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "\n",
    "        # make mask\n",
    "        mask = probability_n >= new_threshold\n",
    "    else:\n",
    "        print(model_predictions.shape)\n",
    "\n",
    "        mask = model_predictions == 1\n",
    "\n",
    "        # Ensure each row has at least one '1'\n",
    "        # no_positive_class is a column vector\n",
    "        # Find rows with all False (no '1') # rows with all false becomes true\n",
    "        no_positive_class = ~mask.any(axis=1) \n",
    "        \n",
    "        # Expand mask by adding a new first column of zeros\n",
    "        mask = np.column_stack((no_positive_class, mask))\n",
    "    \n",
    "\n",
    "    sample_classes = []\n",
    "    for row in mask:\n",
    "        passing_indices = np.where(row)[0]\n",
    "        if len(passing_indices) > 1:  # If more than one indices pass\n",
    "            if not onehot_labels: \n",
    "                # calc exceedances    \n",
    "                exceedances = row - new_threshold\n",
    "                # Get class with the highest exceedance\n",
    "                max_class = np.argmax(exceedances)\n",
    "                sample_classes.append(max_class)\n",
    "            else:\n",
    "                sample_classes.append(tuple(sorted(passing_indices)))  # Ensure passing indices are sorted in ascending order\n",
    "        elif len(passing_indices) == 0:  # no passes\n",
    "            sample_classes.append(0) \n",
    "        else:\n",
    "            sample_classes.append(passing_indices[0])  \n",
    "\n",
    "    return sample_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 6)\n"
     ]
    }
   ],
   "source": [
    "# load predictions to make y_pred\n",
    "model_predictions = np.load(\"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/dnn_output.npy\")\n",
    "# make y_pred\n",
    "y_pred = ECG_one_d_labels(model_predictions, onehot_labels = False)\n",
    "\n",
    "# make y_true\n",
    "y_true_2D = pd.read_csv('/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/annotations/gold_standard.csv').values\n",
    "# convert 2D to 1D\n",
    "y_true = ECG_one_d_labels(y_true_2D, onehot_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select indices/conditions for CoMTE\n",
    "true_select = 0 #UPDATE HERE FOR OTHER CLASSES\n",
    "pred_select = 0 #UPDATE HERE FOR OTHER CLASSES\n",
    "\n",
    "# find relevant indices\n",
    "indices_test = []\n",
    "for idx, (true, pred) in enumerate(zip(y_true, y_pred)):\n",
    "    print(f\"Index:{idx}, True Label: {true}, Predicted Label: {pred}\") # print elements\n",
    "    if true ==  true_select and pred == pred_select:\n",
    "        indices_test.append(idx)   \n",
    "        \n",
    "print('\\n\\n\\n')\n",
    "print(f\"The {indices_test} indices match the case defined above:\\n(true_select = {true_select}, pred_select = {pred_select})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select testing point\n",
    "\n",
    "# get testing point\n",
    "test_point = seq._getsample_(253)\n",
    "# wrap test point \n",
    "test_df = ClfData.wrap_df_test_point(test_point)\n",
    "\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Select Nearest Neighbor Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for getting nearest neighbor samples\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KDTree\n",
    "class nearest_neighbor_samples:\n",
    "    '''\n",
    "        Purpose: \n",
    "        - find true positives\n",
    "        - append them to KDTree\n",
    "        - find nearest neighbor samples that are true positives of the same class\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self, clf, timeseries, labels, silent=True,\n",
    "                     num_distractors=2, dont_stop=False):#,\n",
    "                     # threads=multiprocessing.cpu_count()):\n",
    "        self.clf = clf\n",
    "        self.timeseries = timeseries\n",
    "        self.labels = labels\n",
    "        self.silent = silent\n",
    "        self.num_distractors = num_distractors\n",
    "        if hasattr(clf, \"metrics\") and clf.metrics is not None:\n",
    "            self.metrics = clf.metrics\n",
    "        else:\n",
    "            self.metrics = self.clf.steps[0][1].column_names\n",
    "        self.dont_stop = dont_stop\n",
    "        if hasattr(clf, \"window_size\") and clf.window_size is not None:\n",
    "            self.window_size = clf.window_size\n",
    "        else:\n",
    "            self.window_size = len(timeseries.loc[\n",
    "                timeseries.index.get_level_values('node_id')[0]])\n",
    "        self.tree = None\n",
    "        self.per_class_trees = None\n",
    "        #self.threads = threads\n",
    "        self.classes_to_test = [1,2,3,4,5,6]\n",
    "        \n",
    "\n",
    "    \n",
    "    def construct_per_class_trees(self):\n",
    "            \"\"\"Used to choose distractors\"\"\"\n",
    "            if self.per_class_trees is not None:\n",
    "    \n",
    "                for c, tree in self.per_class_trees.items():\n",
    "                    num_indices = len(tree.data)  # The number of points in the KDTree\n",
    "                    print(f\"Class {c} has {num_indices} indices.\")\n",
    "                return\n",
    "            self.per_class_trees = {}\n",
    "            self.per_class_node_indices = {c: [] for c in self.clf.classes_}\n",
    "            print('making predictions for per class trees')\n",
    "            preds = self.clf.predict(self.timeseries)\n",
    "    \n",
    "            from collections import Counter\n",
    "            #checking preds ...\n",
    "            print('Validate Predictions')\n",
    "            counter = Counter(preds)\n",
    "            # Print unique items and their frequencies\n",
    "            for item, freq in counter.items():\n",
    "                print(f\"{item}: {freq}\")\n",
    "    \n",
    "            true_positive_node_ids = {c: [] for c in self.clf.classes_}\n",
    "            \n",
    "            for pred, (idx, row) in zip(preds, self.labels.iterrows()):\n",
    "                if isinstance(row['label'], tuple):  # skip tuples for now - not sure how to handle them in MLRose Optimization\n",
    "                    continue\n",
    "                if row['label'] == pred:\n",
    "                    if isinstance(idx, int): # wrap single datapoints in array\n",
    "                        idx = [idx]\n",
    "                    true_positive_node_ids[pred].append(idx[0])\n",
    "        \n",
    "            # validation\n",
    "            print(\"\\nTrue Positive Dictionary Stats\")\n",
    "            for key, value in true_positive_node_ids.items():\n",
    "                print(f\"Key: {key}, Length of value: {len(value)}\")\n",
    "            \n",
    "            \n",
    "            print('making per class trees')\n",
    "            print(self.clf.classes_)\n",
    "            for c in self.clf.classes_:\n",
    "                print(c)\n",
    "                dataset = []\n",
    "                for node_id in true_positive_node_ids[c]:\n",
    "                    # The below syntax of timeseries.loc[[node_id], :, :] is extremely fragile. The first two ranges index into the multi-index\n",
    "                    # while the third range indexes the columns. But anything other than \":\" for the third range causes the code to crash, apparently\n",
    "                    # due to ambiguity. See the Warning here: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#using-slicers\n",
    "                    try:\n",
    "                        sliced_node = self.timeseries.loc[[node_id], :, :]\n",
    "                    except pd.errors.IndexingError: # try slicing with fallback\n",
    "                        sliced_node = self.timeseries.loc[[node_id], :]\n",
    "                    dataset.append(sliced_node.values.T.flatten())\n",
    "                    self.per_class_node_indices[c].append(node_id)\n",
    "                if dataset:\n",
    "                    self.per_class_trees[c] = KDTree(np.stack(dataset))\n",
    "            if not self.silent:\n",
    "                logging.info(\"Finished constructing per class kdtree\")\n",
    "\n",
    "\n",
    "    def get_random_tps(self):\n",
    "        '''\n",
    "            This function should generate one random sample for each class in self.classes_to_test\n",
    "\n",
    "        '''\n",
    "        # print out the structure of the KD tree\n",
    "        print(\"\\nKDTree structure (underlying tree representation):\")\n",
    "        print(self.per_class_trees)\n",
    "\n",
    "        \n",
    "        # get a random sample for each class in KDTree, store in tuple\n",
    "        random_samples = []\n",
    "\n",
    "        for c in self.classes_to_test:\n",
    "            if c in self.per_class_trees:  # Ensure the class has a KDTree\n",
    "                # Get a random index from the class tree\n",
    "                random_idx = np.random.randint(len(self.per_class_trees[c].data))\n",
    "                print(f'random index is {random_idx}')\n",
    "                # extract distractor\n",
    "                random_sample = self.timeseries.loc[[self.per_class_node_indices[c][random_idx]], :, :]\n",
    "                random_samples.append((c, random_sample))\n",
    "            else:\n",
    "                print(f\"No KDTree found for class {c}\")\n",
    "        return random_samples\n",
    "\n",
    "\n",
    "    def get_all_samples(self):\n",
    "        '''\n",
    "            This funciton should generate all samples, and store them in tuples\n",
    "        '''\n",
    "        print('Getting all samples')\n",
    "        # start with constructing per class KD trees\n",
    "        self.construct_per_class_trees()\n",
    "\n",
    "        # get random true positives\n",
    "        random_samples = self.get_random_tps()\n",
    "\n",
    "        # iterate through each of the random samples to get Knn\n",
    "        n_distractors = 2\n",
    "\n",
    "        # Initialize a list to store distractors (nearest neighbors)\n",
    "        distractors = defaultdict(list)\n",
    "        print(len(random_samples))\n",
    "        # For each random sample, find nearest neighbors\n",
    "        for class_id, sample in random_samples:\n",
    "            print(class_id)\n",
    "            print(sample)\n",
    "            # code for querying...\n",
    "            for idx in self.per_class_trees[class_id].query(\n",
    "                sample.values.T.flatten().reshape(1, -1),\n",
    "                k=n_distractors)[1].flatten():\n",
    "                \n",
    "                print(f'idx for nn distractor is: {idx}')\n",
    "                \n",
    "                try:\n",
    "                    sliced_distractor = self.timeseries.loc[[self.per_class_node_indices[class_id][idx]], :, :]\n",
    "                except pd.errors.IndexingError: # try slicing with fallback\n",
    "                    sliced_distractor = self.timeseries.loc[[self.per_class_node_indices[class_id][idx]], :]\n",
    "                    sliced_distractor['node_id'] = [idx]\n",
    "                    sliced_distractor.set_index('node_id', inplace=True) # aka sample_id\n",
    "                \n",
    "                distractors[class_id].append((class_id, sliced_distractor))\n",
    "        \n",
    "        return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifier methods\n",
    "\n",
    "\"\"\"\n",
    "Part 1: A Classifier that works with COMLEX\n",
    "\n",
    "The classifier must have 2 capabilities:\n",
    "1. Predict a class ie: class 0 in classes {0, 1}\n",
    "2. Predict the probability for each class\n",
    "-ie: [0.1, 0.9]\n",
    "\n",
    "and\n",
    "\n",
    "Be able to execute capability 1 and 2 on a PANDAS dataframe,\n",
    "returning an array of corresponding predictions.\n",
    "\n",
    "\n",
    "\n",
    "input:\n",
    "    samples to be classified (pandas multiindex dataframe)\n",
    "\n",
    "output: \n",
    "    for contrived_classification: length N list of classes\n",
    "\n",
    "    for contrived_classification_proba: \n",
    "            length N list of 1x7 np arrays\n",
    "\"\"\"\n",
    "\n",
    "# load pretrained model (still need to compile later) \n",
    "model_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/PretrainedModels/model/model.hdf5\"\n",
    "pre_model = load_model(model_path)  \n",
    "pre_model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "\n",
    "class BasicClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "    import os\n",
    "    \n",
    "    @staticmethod\n",
    "    def contrived_classification(pandas_dfs):\n",
    "        import os\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "        # convert 2D pandas df to 3D dataframe (N,4096,12)\n",
    "        array_3d = pandas_dfs.to_numpy().reshape(int(pandas_dfs.shape[0]/4096), 4096, 12)\n",
    "\n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 0)    \n",
    "        \n",
    "    \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        # analyze model output with thresholding\n",
    "        # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        \n",
    "        # Add normal_prob as a new column\n",
    "        probability_n = np.column_stack((normal_prob, probability))     \n",
    "\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        mask = probability_n >= new_threshold\n",
    "        sample_classes = []  # init list for appends later\n",
    "        \n",
    "        for row, mask in zip(probability_n, mask):\n",
    "            passing_indices = np.where(mask)[0]\n",
    "            if len(passing_indices) > 1:  # If more than one indices pass\n",
    "                # find margin between threshold and probability\n",
    "                diff_array = row - new_threshold\n",
    "                passing_index = np.argmax(diff_array)\n",
    "                # append the index that has the highest margin\n",
    "                sample_classes.append(passing_index)\n",
    "            \n",
    "            elif len(passing_indices) == 0:  # no passes\n",
    "                sample_classes.append(0) \n",
    "            else:\n",
    "                sample_classes.append(passing_indices[0])  # Select the first (or adjust logic)\n",
    "                \n",
    "        return sample_classes\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def contrived_classification_proba(pandas_dfs):\n",
    "        import os\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "        \n",
    "        # convert 2D pandas df to 3D dataframe (N,4096,12)\n",
    "        array_3d = pandas_dfs.to_numpy().reshape(int(pandas_dfs.shape[0]/4096), 4096, 12)\n",
    "\n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 0)  \n",
    "        \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        # analyze model output with thresholding\n",
    "         # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances)\n",
    "\n",
    "        # modify result \n",
    "        probability = np.insert(probability,0,normal_prob)   \n",
    "\n",
    "        # probability should be in a 2D array format\n",
    "        if probability.ndim == 1:  # Check if it's 1D\n",
    "            probability = probability.reshape(1, -1)\n",
    "        \n",
    "        return probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert x_train from np into pandas\n",
    "hdf5_test_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/combined_V2.hdf5\"\n",
    "hdf5_test_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "\n",
    "dataset_name_hdf_tracings = 'tracings'\n",
    "f = h5py.File(hdf5_test_path, \"r\")\n",
    "x_test = np.array(f[dataset_name_hdf_tracings])\n",
    "num_features = 12\n",
    "pd_test_points = ClfData.wrap_df_x(x_test, num_features)\n",
    "\n",
    "# make y_test (2D one-hot --> 1D)\n",
    "y_true_2D = pd.read_csv('/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/labels_combined_V2.csv').values\n",
    "y_true_2D = pd.read_csv('/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/annotations/gold_standard.csv').values\n",
    "y_test = ClfData.wrap_df_y(y_true_2D)\n",
    "\n",
    "# wrap model\n",
    "classes_available = [0,1,2,3,4,5,6]\n",
    "num_columns = 4096\n",
    "wrapped_classifier = ClfModel(BasicClassifier.classifier,\n",
    "                            predict_attr=BasicClassifier.contrived_classification,\n",
    "                            predict_proba_attr=BasicClassifier.contrived_classification_proba,\n",
    "                            column_attr=pd_test_points.columns.values.tolist(),\n",
    "                            classes_attr=classes_available,\n",
    "                            window_size_attr=num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize \n",
    "nn_sampler = nearest_neighbor_samples(\n",
    "    clf=wrapped_classifier,\n",
    "    timeseries=pd_test_points,\n",
    "    labels=y_test,\n",
    "    silent=False,             # show log info\n",
    "    num_distractors=3,        # 3 neighbors per class\n",
    "    dont_stop=True            # unclear what this does, but included for completeness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples = nn_sampler.get_all_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(samples))\n",
    "#print((samples))\n",
    "\n",
    "for class_id, items in samples.items():\n",
    "    print(f\"\\nClass ID: {class_id}\")\n",
    "    print(f\"Number of items: {len(items)}\")\n",
    "    for i, (cls, data) in enumerate(items):\n",
    "        print(f\"  Item {i}: type = {type(data)}\")\n",
    "        if hasattr(data, \"shape\"):\n",
    "            print(f\"    shape = {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Lipschiz Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructor for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CoMTE\n",
    "sys.path.append('/projectnb/peaclab-mon/JLi/projectx/CoMTE_V2_JLi/CoMTE_V2/comlex_core/src')  # Path to the comlex_core directory\n",
    "import explainers as explainers_V2\n",
    "import itertools\n",
    "\n",
    "class BasicData:\n",
    "    # define basic variables\n",
    "    classes_available = [0,1,2,3,4,5,6]\n",
    "    num_columns = 4096\n",
    "    num_features = 12\n",
    "\n",
    "    # define paths and variables for training data\n",
    "    path_to_hdf5_test = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/CODE/ecg_tracings.hdf5\"\n",
    "    dataset_name_hdf_tracings = \"tracings\" \n",
    "    training_set_hdf_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/combined_V2.hdf5\"\n",
    "    y_train_csv_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/labels_combined_V2.csv\"\n",
    "    \n",
    "    f = h5py.File(training_set_hdf_path, \"r\")\n",
    "    timeseries = np.array(f[dataset_name_hdf_tracings])\n",
    "\n",
    "    # iterable of corresponding labels for the samples for the data wrapper (returns 20000x6 np array) <--- take out first column that represents ExamID\n",
    "    labels = pd.read_csv(y_train_csv_path)\n",
    "\n",
    "\n",
    "class BasicComlexInput:\n",
    "\n",
    "    # 1. wrap training points\n",
    "    df_train_points = ClfData.wrap_df_x(BasicData.timeseries, BasicData.num_features)\n",
    "    \n",
    "    # 2. wrap training labels\n",
    "    df_train_labels = ClfData.wrap_df_y(BasicData.labels)\n",
    "\n",
    "    # 3. wrap up the classifier\n",
    "    # note: column_attr, or the corresponding name of the columns in the sample,\n",
    "    #  is unique to dataframes, and auto-generated by wrap_df_x\n",
    "    # wrapped_classifier = ClfModel(BasicClassifier.classifier,\n",
    "    #                             predict_attr=BasicClassifier.contrived_classification,\n",
    "    #                             predict_proba_attr=BasicClassifier.contrived_classification_proba,\n",
    "    #                             column_attr=df_train_points.columns.values.tolist(),\n",
    "    #                             classes_attr=BasicData.classes_available,\n",
    "    #                             window_size_attr=BasicData.num_columns)    \n",
    "    \n",
    "    # get testing point\n",
    "    test_point = seq._getsample_(253)\n",
    "    # wrap test point \n",
    "    test_df = ClfData.wrap_df_test_point(test_point)\n",
    "\n",
    "\n",
    "# set up an optimized search comlex runner\n",
    "# note: classifier was set up above\n",
    "comlex = explainers_V2.OptimizedSearch(wrapped_classifier,\n",
    "                                    BasicComlexInput.df_train_points,\n",
    "                                    BasicComlexInput.df_train_labels,\n",
    "                                    silent=True, threads=4, num_distractors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over the dictionary\n",
    "results_df = pd.DataFrame(columns=['class', 'exp_diff', 'clf_diff', 'lipschitz'])\n",
    "\n",
    "for key, tuple_list in samples.items():\n",
    "    print(f\"Class: {key}\")\n",
    "    \n",
    "    # Get all 2-tuple combinations\n",
    "    for t1, t2 in itertools.combinations(tuple_list, 2):\n",
    "        # Flatten both DataFrames\n",
    "        vec1 = t1[1].values.flatten()\n",
    "        vec2 = t2[1].values.flatten()\n",
    "\n",
    "        # get explanations\n",
    "        explanation_t1 = comlex.explain(t1[1],to_maximize=key,\n",
    "                             return_dist=True,single=True,\n",
    "                             savefig=True,train_iter=100,\n",
    "                             timeseries=False,filename=\"sample_result.png\")\n",
    "        explanation_t2 = comlex.explain(t2[1],to_maximize=key,\n",
    "                             return_dist=True,single=True,\n",
    "                             savefig=True,train_iter=100,\n",
    "                             timeseries=False,filename=\"sample_result.png\")\n",
    "        \n",
    "        # convert into sets for set distance\n",
    "        exp_t1_set = set(explanation_t1[1].values.flatten())  \n",
    "        exp_t2_set = set(explanation_t2[1].values.flatten())  \n",
    "        # calculate set distance between explanations\n",
    "        exp_diff = len(exp_t1_set.difference(exp_t2_set)) + len(exp_t2_set.difference(exp_t1_set))\n",
    "        \n",
    "        # Compute Euclidean distance between samples\n",
    "        clf_diff = np.linalg.norm(vec1 - vec2)\n",
    "        \n",
    "        # calculate lipschiz ratio\n",
    "        lipschitz = exp_diff / clf_diff\n",
    "\n",
    "        # Store results in the DataFrame\n",
    "        new_row = pd.DataFrame({\n",
    "            'class': [key],\n",
    "            'exp_diff':[exp_diff],\n",
    "            'clf_diff':[clf_diff],\n",
    "            'lipschitz': [lipschitz]\n",
    "        })\n",
    "        results_df = pd.concat([results_df,new_row],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "import shap\n",
    "\n",
    "\"\"\"\n",
    "SHAP Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "class BasicSHAPInput:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "    # wrap training points for SHAP\n",
    "    df_train_points_SHAP = ClfData.wrap_df_x_SHAP(BasicData.timeseries, BasicData.num_features)\n",
    "\n",
    "    # select test point \n",
    "    test_point = seq._getsample_(253)\n",
    "    \n",
    "    # wrap test point for SHAP\n",
    "    test_df_SHAP = ClfData.wrap_df_test_point_SHAP(test_point)\n",
    "\n",
    "class BasicSHAPClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "# X_train_background is typically a small representative subset of X_train\n",
    "BasicSHAPInput.df_train_points_SHAP.shape\n",
    "\n",
    "# init explainer\n",
    "explainer = shap.GradientExplainer(BasicSHAPClassifier.classifier, BasicSHAPInput.df_train_points_SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "\n",
    "shap_values = explainer.shap_values(BasicSHAPInput.test_df_SHAP)\n",
    "print(shap_values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "LIME Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SHAP Wrappers for input data, model\n",
    "\"\"\"\n",
    "\n",
    "class BasicLIMEClassifier:\n",
    "    classifier = pre_model  # tensorflow CNN\n",
    "    import os\n",
    "    @staticmethod\n",
    "    def contrived_classification(pandas_dfs):\n",
    "        \"\"\"\n",
    "        Notes: \n",
    "            if there were multiple classes that exceeded the threshold, the class with the highest exceedance was assigned\n",
    "            to the sample\n",
    "\n",
    "        Input: \n",
    "            numpy_df: pandas multiindex array of samples\n",
    "\n",
    "        Output: \n",
    "            if there is one sample: function returns the index\n",
    "            if there are multiple samples: function returns a (1xN) list of the indices\n",
    "        \"\"\"\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "        \n",
    "        # create instance of ECGSequence to store the (N,4096,12) dataset\n",
    "        temp_path = \"/projectnb/peaclab-mon/JLi/projectx/AutoECGDiagnosisData/temporary.hdf5\"\n",
    "        temp_dataset_name = \"tracings\"\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        # create hdf with appropriate data\n",
    "        hdf_file = h5py.File(temp_path, 'w')\n",
    "        hdf_file.create_dataset(temp_dataset_name,data = array_3d)\n",
    "        # init instnace of ECG Sequence holding modified with hdf path\n",
    "        modified_instance = datasets.ECGSequence(temp_path, temp_dataset_name)\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(modified_instance, verbose = 1)    \n",
    "        # close hdf5's\n",
    "        modified_instance._closehdf()\n",
    "        hdf_file.close()\n",
    "        os.remove(temp_path)\n",
    "        # analyze model output with thresholding\n",
    "        # define given thresholds\n",
    "        threshold = np.array([0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        # generate class 0 probability\n",
    "        exceedances = 1 - (np.maximum((probability - threshold) , 0) / (1 - threshold))\n",
    "        normal_prob = np.mean(exceedances, axis = 1, keepdims = True) # normal prob should be (N,1)\n",
    "        \n",
    "        # Add normal_prob as a new column\n",
    "        probability_n = np.column_stack((normal_prob, probability))     \n",
    "\n",
    "        # new threshold\n",
    "        new_threshold = np.array([1, 0.124, 0.07, 0.05, 0.278, 0.390, 0.174])\n",
    "        \n",
    "        mask = probability_n >= new_threshold\n",
    "        sample_classes = []\n",
    "        \n",
    "        for row, mask in zip(probability_n, mask):\n",
    "            passing_indices = np.where(mask)[0]\n",
    "            if len(passing_indices) > 1:  # If more than one indices pass\n",
    "                # compute exceedance\n",
    "                exceedances = row[passing_indices] - new_threshold[passing_indices]\n",
    "                # Get class with the highest exceedance\n",
    "                max_class = passing_indices[np.argmax(exceedances)]\n",
    "                sample_classes.append(max_class)\n",
    "            elif len(passing_indices) == 0:  # no passes\n",
    "                sample_classes.append(0) \n",
    "            else:\n",
    "                sample_classes.append(passing_indices[0])  \n",
    "                \n",
    "        # don't return list if only one sample\n",
    "        if len(sample_classes) == 1:\n",
    "            sample_classes = sample_classes[0]\n",
    "        \n",
    "        return sample_classes \n",
    "    \n",
    "    # LIME prediction function...\n",
    "    def contrived_classification_proba_LIME(np_2d_array):\n",
    "        import os\n",
    "        \"\"\"\n",
    "        Purpose: \n",
    "            make prediction and return set of probabilities\n",
    "        Return: \n",
    "            if there are single or multiple samples: function returns a list of arrays containing the probabilities\n",
    "        \"\"\"\n",
    "\n",
    "        # reshape\n",
    "        num_features = np_2d_array.shape[0]\n",
    "        print(f\"num features is {num_features}\")\n",
    "        df_reshaped = np_2d_array.reshape(num_features, 4096, 12)\n",
    "\n",
    "        # init classifier\n",
    "        classifier = pre_model  # tensorflow CNN\n",
    "\n",
    "        # get classification and probability\n",
    "        probability = classifier.predict(df_reshaped, verbose = 1)  \n",
    "        \n",
    "        return probability\n",
    "        \n",
    "class BasicLIMEInput:\n",
    "    classifier = pre_model  # tensorflow CNN    \n",
    "\n",
    "    # wrap training points for LIME\n",
    "    df_train_points_LIME = ClfData.wrap_df_x_LIME(BasicData.timeseries, BasicData.num_features)\n",
    "    \n",
    "    # wrap training labels \n",
    "    df_train_labels = ClfData.wrap_df_y(BasicData.labels)\n",
    "    \n",
    "    # select test point \n",
    "    test_point = seq._getsample_(253)\n",
    "\n",
    "    # wrap test point for LIME\n",
    "    test_df_LIME = ClfData.wrap_df_test_point_LIME(test_point)\n",
    "\n",
    "\n",
    "    # wrap classifier for LIME\n",
    "    wrapped_classifier_LIME = ClfModel(BasicLIMEClassifier.classifier,\n",
    "                                predict_attr=BasicLIMEClassifier.contrived_classification,\n",
    "                                predict_proba_attr=BasicLIMEClassifier.contrived_classification_proba_LIME,\n",
    "                                column_attr=['DI','DII','DIII','AVR','AVL','AVF','V1','V2','V3','V4','V5','V6'],\n",
    "                                classes_attr=BasicData.classes_available,\n",
    "                                window_size_attr=BasicData.num_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import lime.lime_tabular as limetabular\n",
    "\n",
    "# instantiate LIME tabular explainer\n",
    "'''\n",
    "    input: \n",
    "    1. flattened data (N,49152) <-- flattened in row-major order (C-style)\n",
    "    2. model\n",
    "    3. feature names \n",
    "    4. classification\n",
    "'''\n",
    "LIME_explainer = limetabular.LimeTabularExplainer(BasicLIMEInput.df_train_points_LIME, \n",
    "                                                  mode = 'classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.DEBUG)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries, labels, test_timeseries, test_labels = data_loading.load_hpc_data(\n",
    "    # Path('/home/ates/data/taxonomist/'), window=60, skip=60, make_binary=True)\n",
    "    Path('/projectnb/peaclab-mon/ates/hpas'), classes=['memorybandwidth', 'none'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "!pip install scikit-learn==0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "good_kwargs = []\n",
    "for p in ['l1', 'l2', 'elasticnet', 'none']:\n",
    "    for tol in np.logspace(-8, -1, 8):\n",
    "        for solver in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "            for c in np.logspace(-8, 8, 20) if p != 'none' else [1]:\n",
    "                kwargs = {'penalty': p, 'tol': tol, 'C': c, 'solver': solver, 'fit_intercept': False}\n",
    "                try:\n",
    "                    clf = LogisticRegression(**kwargs)\n",
    "                    clf.fit([[1], [0]], [1, 0])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                else:\n",
    "                    good_kwargs.append(kwargs)\n",
    "print(len(good_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_kwargs = []\n",
    "pipelines = []\n",
    "scores = []\n",
    "random.shuffle(good_kwargs)\n",
    "\n",
    "\n",
    "# pull out feature extraction\n",
    "\n",
    "\n",
    "for kwargs in tqdm(good_kwargs):\n",
    "    \n",
    "    p = Pipeline([\n",
    "        ('assert1', analysis.classifier.CheckFeatures()),\n",
    "        ('features', analysis.data.TSFeatureGenerator(threads=1, trim=0)),\n",
    "        ('assert2', analysis.classifier.CheckFeatures()),\n",
    "        ('scaler', MinMaxScaler(feature_range=(-1, 1))),\n",
    "        ('clf', LogisticRegression(**kwargs))\n",
    "    ])\n",
    "\n",
    "    p.fit(timeseries, np.ravel(labels))\n",
    "    preds = p.predict(test_timeseries)\n",
    "    score = f1_score(test_labels, preds, average='weighted')\n",
    "    \n",
    "    to_add = False\n",
    "    if score > 0.975:\n",
    "        to_add = True\n",
    "        for p2 in pipelines:\n",
    "            if np.linalg.norm(p.steps[4][1].coef_ - p2.steps[4][1].coef_) == 0:\n",
    "                to_add = False\n",
    "    if not to_add:\n",
    "        continue\n",
    "    scores.append(score)\n",
    "    pipelines.append(p)\n",
    "    used_kwargs.append(kwargs)\n",
    "    if len(pipelines) >= 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_constructors = {\n",
    "    'lime': explainers.LimeExplanation,\n",
    "    'random': explainers.RandomExplanation,\n",
    "    'shap': explainers.ShapExplanation,\n",
    "    'our_method': explainers.BruteForceSearch,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for node_id in tqdm(random.sample(list(test_timeseries.index.get_level_values('node_id').unique()), 50)):\n",
    "    x_test = test_timeseries.loc[[node_id], :, :]\n",
    "    for e in explainer_constructors:\n",
    "        explanations = []\n",
    "        for p in pipelines:\n",
    "            exp = explainer_constructors[e](p, timeseries, labels)\n",
    "            explanations.append(set(exp.explain(x_test)))\n",
    "        min_ratio = 0\n",
    "        for clf1 in range(len(pipelines)):\n",
    "            for clf2 in range(clf1):\n",
    "                clf_diff = np.linalg.norm(pipelines[clf1].steps[4][1].coef_ - pipelines[clf2].steps[4][1].coef_)\n",
    "                print(pipelines[clf1].steps[4][1])\n",
    "                print(pipelines[clf2].steps[4][1])\n",
    "                \n",
    "                exp_diff = len(explanations[clf1].difference(explanations[clf2])) + len(explanations[clf2].difference(explanations[clf1]))\n",
    "                lipschitz = -1 * exp_diff / clf_diff\n",
    "                if lipschitz < min_ratio:\n",
    "                    min_ratio = lipschitz\n",
    "        results.append({\n",
    "            'method': e,\n",
    "            'node_id': node_id,\n",
    "            'ratio': min_ratio,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lipschitz'] = df['ratio'].apply(lambda x: - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df, x='method', y='lipschitz', kind='box', order=['our_method', 'lime', 'shap', 'random'])#, showfliers=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
