{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1e9a41",
   "metadata": {},
   "source": [
    "Classes provde a means of bundling data and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec31b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'turtle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab23d5c8f022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mturtle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'turtle'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class polygon:\n",
    "    def __init__(self, sides, name):\n",
    "        self.sides = sides\n",
    "        self.name = name\n",
    "        \n",
    "    def draw(self):\n",
    "        for for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = polygon(4, \"square\")\n",
    "pent = polygon(5,\"pentagon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from copy import deepcopy\n",
    "\n",
    "# standardScaler standardizes, minmaxscaler changes values between 0-1\n",
    "# pandas dataframe = 2D dataframe, heterogeneous\n",
    "# numpy dataframe = ND dataframe, homogeneous\n",
    "\n",
    "\n",
    "\n",
    "# read into pandas dataframe\n",
    "train_df = pd.read_csv('sample.csv')\n",
    "test_df = pd.read_csv('sample_test.csv')\n",
    "\n",
    "\n",
    "# convert to numpy dataframe\n",
    "X_train, y_train = train_df.to_numpy()[:,:-1], train_df.to_numpy()[:,-1]\n",
    "X_test, y_test = test_df.to_numpy()[:,:-1], train_df.to_numpy()[:,-1]\n",
    "\n",
    "\n",
    "# goal: fit a transformer (two different scalers to different columns)\n",
    "\n",
    "std_scaler = StandardScaler().fit(X_train[:,:2]) # indicates all rows, but first 2 columns\n",
    "min_max_scaler = MinMaxScaler().fit(X_train[:,2:]) # indicates all rows and all columns except the first two\n",
    "\n",
    "\n",
    "# make a function that incorporates\n",
    "def preprocessor (X):\n",
    "    A = np.copy(X)\n",
    "    A[:,:2]= std_scaler.transform(X[:,:2])\n",
    "    A[:,2:]= min_max_scaler.transform(X[:,2:])\n",
    "    return A\n",
    "\n",
    "# call preprocessor on X_test that will do the required transformations on the X_test dataset\n",
    "preprocessor(X_test)\n",
    "\n",
    "preprocess_transformer = FunctionTransformer(preprocessor)\n",
    "\n",
    "\n",
    "# import pipeline function from sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "p1 = Pipeline([('Scaler', preprocess_transformer),\n",
    "              ('Linear Regression', LinearRegression())])\n",
    "\n",
    "# p1 is our first pipeline. it performs a scaler and min_max transform from preprocess_transformer\n",
    "# then, it fits a Linear Regression\n",
    "# .fit for a pipeline fits the scalers (min_max, standard) and model (linear regression)\n",
    "# .predict for a pipeline uses the structre to make predictions on a given dataset\n",
    "\n",
    "\n",
    "#\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def fit_and_print(p, X_train = X_train, y_train=y_train, x_test = X_test, t_test = y_test)\n",
    "    \n",
    "    # fit the elements in the pipeline\n",
    "    p.fit(X_train,y_train) # fit the transform\n",
    "\n",
    "    # form predictions on given dataset\n",
    "    train_preds = p.predict(x_train)\n",
    "    test_preds = p.predict(X_test)\n",
    "\n",
    "    # print train/test errors\n",
    "    print('Training error:' + str(mean_absolute_error(train_preds, y_train)))\n",
    "    print('Testing error:' + str(mean_absolute_error(test_preds,y_test)))\n",
    "\n",
    "# run fit_and_print\n",
    "fit_and_print(p1)\n",
    "\n",
    "\n",
    "# try knn regression model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNR\n",
    " \n",
    "p2 = Pipeline([('Scaler', preprocess_transformer),\n",
    "              ('KNN Regression', KNR(n_neighbors = 7))])\n",
    "\n",
    "\n",
    "# run fit and print for new model\n",
    "fit_and_print(p2)\n",
    "\n",
    "\n",
    "# make a random forest pipeline (p3)\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "\n",
    "p3 = Pipeline([('Scaler', preprocess_transformer),\n",
    "              ('Random Forest Classifier', RFR(n_estimators = 10, max_depth = 7))])   \n",
    "fit_and_print(p3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
