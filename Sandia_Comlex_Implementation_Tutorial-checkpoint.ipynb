{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c809a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is a basic tutorial on how to use COMLEX in 4 parts\\n\\nParts 1 and 2 are to set up a classifier and a dataset used\\nto train the classifier, which you will usually have already.\\n\\n\\nPart 3 shows how to connect the classifier and dataset into\\na wrapper that can be input to the COMLEX algorithm, by using\\nhelper functions found in COMLEX's explainable_model and\\nexplainable_data files. More info can be found in their\\nrespective files.\\n\\nPart 4 shows the actual execution of COMLEX, after the input\\ncomponents have been wrapped up with COMLEX's utility function.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('/projectnb/peaclab-mon/JLi/projectx/CoMTE_V2/comlex_core')  # Path to the comlex_core directory\n",
    "\n",
    "\n",
    "# treat src as a package since it has an __init__.py file\n",
    "from src import explainers\n",
    "from src.explainable_model import ClfModel\n",
    "from src.explainable_data import ClfData\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is a basic tutorial on how to use COMLEX in 4 parts\n",
    "\n",
    "Parts 1 and 2 are to set up a classifier and a dataset used\n",
    "to train the classifier, which you will usually have already.\n",
    "\n",
    "\n",
    "Part 3 shows how to connect the classifier and dataset into\n",
    "a wrapper that can be input to the COMLEX algorithm, by using\n",
    "helper functions found in COMLEX's explainable_model and\n",
    "explainable_data files. More info can be found in their\n",
    "respective files.\n",
    "\n",
    "Part 4 shows the actual execution of COMLEX, after the input\n",
    "components have been wrapped up with COMLEX's utility function.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75553f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1: A Classifier that works with COMLEX\n",
    "\n",
    "The classifier must have 2 capabilities:\n",
    "1. Predict a class ie: class 0 in classes {0, 1}\n",
    "2. Predict the probability for each class\n",
    "-ie: [0.1, 0.9]\n",
    "\n",
    "and\n",
    "\n",
    "Be able to execute capability 1 and 2 on a PANDAS dataframe,\n",
    "returning an array of corresponding predictions.\n",
    "\"\"\"\n",
    "\n",
    "class BasicClassifier:\n",
    "    classifier = {} # nothing here, but sklearn classifiers are well supported\n",
    "\n",
    "    @staticmethod\n",
    "    def contrived_classification(pandas_dfs):\n",
    "        results = []\n",
    "        for index, pandas_df in pandas_dfs.iterrows():\n",
    "            running_tot = 0\n",
    "            #-----\n",
    "            for val_i in pandas_df:\n",
    "                running_tot += val_i\n",
    "            res_val = running_tot % 2\n",
    "            if res_val > 1:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "            #-----\n",
    "            # replace above with function giving class, ie: result=0 in result classes {0,1}\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def contrived_classification_proba(pandas_dfs):\n",
    "        results = []\n",
    "        for index, pandas_df in pandas_dfs.iterrows():\n",
    "            running_tot = 0\n",
    "            #-----\n",
    "            for val_i in pandas_df:\n",
    "                running_tot += val_i\n",
    "            res_val = running_tot % 2\n",
    "            results.append([1.0-res_val/2.0, res_val/2.0])\n",
    "            #-----\n",
    "            # replace above with function giving probability of classes, ie: [0.1, 0.9] in classes {0,1} meaning 0.1=0, 0.9=1\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ef92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 2: Training data and labels\n",
    "\n",
    "[The explanation will use counterfactuals drawn from this input data]\n",
    "\n",
    "The training data can be should be an iterable of samples\n",
    "(ie: python array, numpy array, pandas dataframe),\n",
    "where each sample needs to be the same size array as the others.\n",
    "\n",
    "The labels should be a corresponding iterable to the samples.\n",
    "\n",
    "COMLEX will only use samples for which the labels are the same\n",
    "as the prediction from the trained classifier.\n",
    "\n",
    "Note:\n",
    "We don't support variable-length training data at this time,\n",
    "use a different projection of the data if you have such data.\n",
    "\"\"\"\n",
    "\n",
    "class BasicData:\n",
    "    classes_available = [0, 1]\n",
    "\n",
    "    # Random data is generated here and the labels are calculated.\n",
    "    # In this case, 20 samples of 8-length arrays.\n",
    "    num_columns = 8\n",
    "    num_rand_samples = 20\n",
    "    \n",
    "    # create a random dataset\n",
    "    np_train_points = [np.random.rand(8) for _ in range(num_rand_samples)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83826cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 3: Wrapping it up.\n",
    "\n",
    "The training data, training labels, and trained classifier need to be wrapped up\n",
    "into a form that can pass through COMLEX.\n",
    "\n",
    "While wrapping up the training data and labels is relatively straightforward,\n",
    "wrapping up the classifier is more difficult\n",
    "\"\"\"\n",
    "\n",
    "class BasicComlexInput:\n",
    "    # 1. wrap up the training points\n",
    "    df_train_points = ClfData.wrap_df_x(BasicData.np_train_points, BasicData.num_columns)\n",
    "\n",
    "    # 2. generate and wrap up the labels\n",
    "    train_labels = BasicClassifier.contrived_classification(df_train_points)\n",
    "    np_train_labels = np.array(train_labels)\n",
    "    df_train_labels = ClfData.wrap_df_y(np_train_labels)\n",
    "\n",
    "    # 3. wrap up the classifier\n",
    "    # note: column_attr, or the corresponding name of the columns in the sample,\n",
    "    #   is unique to dataframes, and auto-generated by wrap_df_x\n",
    "    wrapped_classifier = ClfModel(BasicClassifier.classifier,\n",
    "                                predict_attr=BasicClassifier.contrived_classification,\n",
    "                                predict_proba_attr=BasicClassifier.contrived_classification_proba,\n",
    "                                column_attr=df_train_points.columns.values.tolist(),\n",
    "                                classes_attr=BasicData.classes_available,\n",
    "                                window_size_attr=BasicData.num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0489d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification of [0.56, 0.32, 0.22, 0.44, 0.44, 0.11, 0.45, 0.24]\n",
      "can be changed from 0 to 1\n",
      "by changing the sample at points {np.int64(1), np.int64(5), np.int64(6)},\n",
      "with points from the distractor:\n",
      "                      0         1         2         3        4         5  \\\n",
      "node_id dummy                                                              \n",
      "3       3      0.364701  0.403356  0.064891  0.354251  0.09459  0.943919   \n",
      "\n",
      "                      6         7  \n",
      "node_id dummy                      \n",
      "3       3      0.666855  0.229296  \n",
      "\n",
      "The modified sample that would lead to a different classification is:\n",
      "[0.56, np.float64(0.40335597145457647), 0.22, 0.44, 0.44, np.float64(0.9439191218325991), np.float64(0.666854667545052), 0.24]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "[0, 1]\n",
      "8\n",
      "                      0         1         2         3         4         5  \\\n",
      "node_id dummy                                                               \n",
      "0       0      0.956389  0.056481  0.578514  0.233139  0.060734  0.916912   \n",
      "1       1      0.761971  0.011392  0.287478  0.072547  0.991379  0.168452   \n",
      "2       2      0.899249  0.340117  0.800955  0.656788  0.896968  0.473051   \n",
      "3       3      0.364701  0.403356  0.064891  0.354251  0.094590  0.943919   \n",
      "4       4      0.444769  0.476536  0.552195  0.671752  0.563831  0.659994   \n",
      "5       5      0.034196  0.552541  0.078117  0.744889  0.673401  0.553940   \n",
      "6       6      0.350229  0.369648  0.745959  0.520821  0.476520  0.288690   \n",
      "7       7      0.920361  0.300263  0.145013  0.088645  0.940407  0.861409   \n",
      "8       8      0.231479  0.896073  0.761438  0.387558  0.507809  0.303456   \n",
      "9       9      0.703127  0.708145  0.290874  0.955205  0.919905  0.904023   \n",
      "10      10     0.572357  0.074501  0.545133  0.063153  0.471518  0.309502   \n",
      "11      11     0.188414  0.661581  0.541175  0.998378  0.677094  0.898507   \n",
      "12      12     0.414235  0.439646  0.764421  0.013158  0.240098  0.464112   \n",
      "13      13     0.699215  0.151810  0.546316  0.405862  0.845641  0.097190   \n",
      "14      14     0.572190  0.403925  0.113386  0.802784  0.819075  0.504547   \n",
      "15      15     0.284897  0.269258  0.490509  0.790186  0.640467  0.802042   \n",
      "16      16     0.253193  0.494156  0.552988  0.649591  0.505794  0.371970   \n",
      "17      17     0.558002  0.578877  0.331104  0.126837  0.661577  0.753130   \n",
      "18      18     0.493315  0.312025  0.257334  0.290775  0.148110  0.941750   \n",
      "19      19     0.427190  0.557289  0.806793  0.427413  0.987874  0.114288   \n",
      "\n",
      "                      6         7  \n",
      "node_id dummy                      \n",
      "0       0      0.141095  0.936146  \n",
      "1       1      0.135788  0.157490  \n",
      "2       2      0.325065  0.721914  \n",
      "3       3      0.666855  0.229296  \n",
      "4       4      0.875071  0.587302  \n",
      "5       5      0.993604  0.916444  \n",
      "6       6      0.323998  0.314953  \n",
      "7       7      0.063295  0.179174  \n",
      "8       8      0.140379  0.498602  \n",
      "9       9      0.384176  0.507234  \n",
      "10      10     0.043321  0.367900  \n",
      "11      11     0.644213  0.683354  \n",
      "12      12     0.738370  0.732826  \n",
      "13      13     0.841165  0.381117  \n",
      "14      14     0.885520  0.808388  \n",
      "15      15     0.646841  0.364325  \n",
      "16      16     0.762171  0.842708  \n",
      "17      17     0.725865  0.447781  \n",
      "18      18     0.306284  0.113956  \n",
      "19      19     0.301131  0.468387  \n",
      "\n",
      "          label\n",
      "dummy          \n",
      "(0, 0)        1\n",
      "(1, 1)        0\n",
      "(2, 2)        1\n",
      "(3, 3)        1\n",
      "(4, 4)        0\n",
      "(5, 5)        0\n",
      "(6, 6)        1\n",
      "(7, 7)        1\n",
      "(8, 8)        1\n",
      "(9, 9)        1\n",
      "(10, 10)      0\n",
      "(11, 11)      1\n",
      "(12, 12)      1\n",
      "(13, 13)      1\n",
      "(14, 14)      0\n",
      "(15, 15)      0\n",
      "(16, 16)      0\n",
      "(17, 17)      0\n",
      "(18, 18)      0\n",
      "(19, 19)      0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part 4: Running it through COMLEX\n",
    "\n",
    "Requires:\n",
    "1. wrapped classifier\n",
    "2. wrapped training data\n",
    "3. wrapped training labels\n",
    "\n",
    "To run COMLEX:\n",
    "1. wrap the test point\n",
    "2. instantiate a comlex runner on the wrapped components\n",
    "-OptimizedSearch sets up a KDTree for based on the data,\n",
    " in order to speed up the search time for the counterfactual\n",
    " explanation.\n",
    "-OptimizedSearch will fallback to BruteForceSearch if it fails\n",
    " to find a counterfactual explanation with a predicted\n",
    " probability greater than 0.95.\n",
    "3. use the comlex runner to explain wrapped datapoint\n",
    "\"\"\"\n",
    "\n",
    "# 1. wrap a test data point whose classification you want to explain\n",
    "test_point = [0.56, 0.32, 0.22, 0.44, 0.44, 0.11, 0.45, 0.24]\n",
    "test_df = ClfData.wrap_df_test_point(test_point)\n",
    "\n",
    "# 2. set up an optimized search comlex runner\n",
    "comlex = explainers.OptimizedSearch(BasicComlexInput.wrapped_classifier,\n",
    "                                    BasicComlexInput.df_train_points,\n",
    "                                    BasicComlexInput.df_train_labels,\n",
    "                                    silent=True, threads=4, num_distractors=3)\n",
    "\n",
    "# 3. explain the test point\n",
    "# make sure target_class != test_df_class, or else comlex.explain does nothing\n",
    "# test_df_class = contrived_classification(test_df) # = 0\n",
    "target_class = 1\n",
    "explanation = comlex.explain(test_df,to_maximize=target_class,\n",
    "                             return_dist=True,single=True,\n",
    "                             savefig=True,#train_iter=10,\n",
    "                             timeseries=False,filename=\"sample_result.png\")\n",
    "\n",
    "replacements = explanation[0]\n",
    "distractor_new = explanation[1]\n",
    "counterfactual_explanation = [point for point in test_point] # make copy of original test data before doing replacements\n",
    "\n",
    "for replacement_i in replacements:\n",
    "    counterfactual_explanation[replacement_i] = distractor_new[replacement_i].values[0]\n",
    "\n",
    "print(f\"The classification of {test_point}\\n\"\n",
    "      f\"can be changed from 0 to {target_class}\\n\" +\n",
    "      f\"by changing the sample at points {explanation[0]},\\n\" +\n",
    "      f\"with points from the distractor:\\n{explanation[1]}\\n\\n\" +\n",
    "      f\"The modified sample that would lead to a different classification is:\\n{counterfactual_explanation}\")\n",
    "\n",
    "print(BasicComlexInput.df_train_points.columns.values.tolist())\n",
    "print(BasicData.classes_available)\n",
    "print(BasicData.num_columns)\n",
    "print(BasicComlexInput.df_train_points)\n",
    "print(\"\")\n",
    "print(BasicComlexInput.df_train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
